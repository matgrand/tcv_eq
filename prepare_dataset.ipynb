{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the training dataset from the equilibria dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing data...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\" # disable GPU\n",
    "import numpy as np\n",
    "from time import time, sleep\n",
    "from os.path import join, exists\n",
    "from utils import *\n",
    "from tqdm import tqdm\n",
    "print(\"Preparing data...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 1000, train samples: 800, eval samples: 200\n"
     ]
    }
   ],
   "source": [
    "# hyperparameters\n",
    "DTYPE = 'float32'\n",
    "RAW_DIR = 'raw_ds' if LOCAL else '/nfsd/automatica/grandinmat/raw_ds' # where the raw data is stored\n",
    "\n",
    "# hyperparameters\n",
    "N_SAMPLES = 1000 if LOCAL else 200_000 #850_000 # number of samples to use for training\n",
    "SM = 1 if LOCAL else 8 # 20 number of grids per samples (SM = SAMPLE MULTIPLIER)\n",
    "TRAIN_EVAL_SPLIT = 0.8 # percentage of the dataset to use for training\n",
    "\n",
    "print(f'Total samples: {N_SAMPLES*SM:.0f}, train samples: {N_SAMPLES*SM*TRAIN_EVAL_SPLIT:.0f}, eval samples: {N_SAMPLES*SM*(1-TRAIN_EVAL_SPLIT):.0f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check RAW_DIR exists and is not empty\n",
    "assert exists(RAW_DIR), f'RAW_DIR {RAW_DIR} does not exist'\n",
    "assert len(os.listdir(RAW_DIR)) > 0, f'RAW_DIR {RAW_DIR} is empty'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i4pirxdzx = 1./(4*pi*L.dzx*L.rx');\n",
    "# i4pirxdrx = 1./(4*pi*L.drx*L.rx');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f: \n",
      "[[  1  66 131 196 261]\n",
      " [  2  67 132 197 262]\n",
      " [  3  68 133 198 263]\n",
      " [  4  69 134 199 264]\n",
      " [  5  70 135 200 265]]\n",
      "a1: (1, 28) [[  63  128  193  258  323  388  453  518  583  648  713  778  843  908\n",
      "   973 1038 1103 1168 1233 1298 1363 1428 1493 1558 1623 1688 1753 1818]]\n",
      "b1: (1, 28) [[  64  129  194  259  324  389  454  519  584  649  714  779  844  909\n",
      "   974 1039 1104 1169 1234 1299 1364 1429 1494 1559 1624 1689 1754 1819]]\n",
      "c1: (1, 28) [[  65  130  195  260  325  390  455  520  585  650  715  780  845  910\n",
      "   975 1040 1105 1170 1235 1300 1365 1430 1495 1560 1625 1690 1755 1820]]\n",
      "a2: (1, 28) [[   3   68  133  198  263  328  393  458  523  588  653  718  783  848\n",
      "   913  978 1043 1108 1173 1238 1303 1368 1433 1498 1563 1628 1693 1758]]\n",
      "b2: (1, 28) [[   2   67  132  197  262  327  392  457  522  587  652  717  782  847\n",
      "   912  977 1042 1107 1172 1237 1302 1367 1432 1497 1562 1627 1692 1757]]\n",
      "c2: (1, 28) [[   1   66  131  196  261  326  391  456  521  586  651  716  781  846\n",
      "   911  976 1041 1106 1171 1236 1301 1366 1431 1496 1561 1626 1691 1756]]\n"
     ]
    }
   ],
   "source": [
    "# calculate Br, Bz (move this to utils.py)\n",
    "def meqBrBz(f:np.ndarray):\n",
    "    if f.ndim == 2: f = f.reshape((1, *f.shape)) \n",
    "    assert f.ndim == 3, f'Input array must be 2D or 3D, got {f.ndim}D'\n",
    "    assert f.shape[1:] == (65, 28), f'Input array must have shape (N, 28, 65), got {f.shape}'\n",
    "    dr, dz, r = RRD[0,1]-RRD[0,0], ZZD[1,0]-ZZD[0,0], RRD[0]\n",
    "    i4pirdr, i4pirdz = 1/(4*np.pi*dr*r), 1/(4*np.pi*dz*r)\n",
    "    # print(f'i4pirdr: {i4pirdr}, \\ni4pirdz: {i4pirdz}, \\nr: {r}, \\ndr: {dr}, \\ndz: {dz}')\n",
    "\n",
    "    Br = Bz = np.zeros_like(f, dtype=DTYPE)\n",
    "    # Br = -1/(2*pi*R)* dF/dz\n",
    "    # Central differences for interior points: F/dz[i] =  F[i-1] - F[i+1]/(2*dz)\n",
    "    Br[:,1:-1,:]    = -i4pirdz *  (f[:,2:,:] - f[:,:-2,:])\n",
    "    # At grid boundary i, use: dF/dz[i] = (-F(i+2) + 4*F(i+1) - 3*F(i))/(2*dz)\n",
    "    a1, b1, c1 = f[:,-3,:], f[:,-2,:], f[:,-1,:]\n",
    "    a2, b2, c2 = f[:,2,:], f[:,1,:], f[:,0,:]\n",
    "\n",
    "    print(f'a1: {a1.shape} {a1}\\nb1: {b1.shape} {b1}\\nc1: {c1.shape} {c1}')\n",
    "    print(f'a2: {a2.shape} {a2}\\nb2: {b2.shape} {b2}\\nc2: {c2.shape} {c2}')\n",
    "\n",
    "    Br[:,-1,:]      = -i4pirdz * (+f[:,-3,:] - 4*f[:,-2,:] + 3*f[:,-1,:])\n",
    "    Br[:,0,:]       = -i4pirdz * (-f[:,2,:]  + 4*f[:,1,:]  - 3*f[:,0,:])\n",
    "\n",
    "    # # Bz = 1/(2*pi*R)* dF/dr\n",
    "    # # Central differences dF/dz[i] =  F[i-1] - F[i+1]/(2*dz)\n",
    "    # Bz[:,:,1:-1]    = i4pirdr[1:-1] * (f[:,:,2:] - f[:,:,:-2])\n",
    "    # # At grid boundary i, use: dF/dz[i] = (-F(i+2) + 4*F(i+1) - 3*F(i))/(2*dz)\n",
    "    # Bz[:,:,-1]      = i4pirdr[-1] * (f[:,:,-3] - 4*f[:,:,-2] + 3*f[:,:,-1])\n",
    "    # Bz[:,:,0]       = i4pirdr[0] *  (-f[:,:,2] + 4*f[:,:,1]  - 3*f[:,:,0])\n",
    "    return Br, Bz\n",
    "\n",
    "f = np.reshape(np.arange(1, 65*28+1), (1, 28, 65)) # dummy data for testing\n",
    "f = np.transpose(f, (0, 2, 1)) # shape (1, 65, 28)\n",
    "print(f'f: \\n{f[0,0:5,0:5]}')\n",
    "Br, Bz = meqBrBz(f)\n",
    "# print(f'Br shape: {Br.shape}, Bz shape: {Bz.shape}')\n",
    "# # print(f'Br: {Br}\\nBz: {Bz}')\n",
    "# print()\n",
    "# print(\"First Br raw:\\n\", Br[0, 0, :])\n",
    "# print(\"Second Br raw:\\n\", Br[0, 1, :])\n",
    "# print(\"Last Br row:\\n\", Br[0, -1, :])\n",
    "# print(\"First Br col:\\n\", Br[0, :, 0])\n",
    "# print(\"Second Br col:\\n\", Br[0, :, 1])\n",
    "# print(\"Last Br col:\\n\", Br[0, :, -1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Found 67 files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading files: 100%|██████████| 67/67 [00:03<00:00, 17.79file/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 67 files.\n",
      "---------------------------------------------------\n",
      "Bm0 -> shape: (26382, 38), dtype: float32\n",
      "Ff0 -> shape: (26382, 38), dtype: float32\n",
      "Ft0 -> shape: (26382, 1), dtype: float32\n",
      "Ia0 -> shape: (26382, 19), dtype: float32\n",
      "Ip0 -> shape: (26382, 1), dtype: float32\n",
      "Iu0 -> shape: (26382, 38), dtype: float32\n",
      "rBt0 -> shape: (26382, 1), dtype: float32\n",
      "Fx -> shape: (26382, 65, 28), dtype: float32\n",
      "Iy -> shape: (26382, 63, 26), dtype: float32\n",
      "Br -> shape: (26382, 65, 28), dtype: float32\n",
      "Bz -> shape: (26382, 65, 28), dtype: float32\n",
      "rq -> shape: (26382, 129), dtype: float32\n",
      "zq -> shape: (26382, 129), dtype: float32\n",
      "---------------------------------------------------\n",
      "-----------------------------------------\n",
      " X -> shape: (26382, 136), dtype: float32\n",
      "i4pirdr: [6.57 6.36 6.17 5.99 5.82 5.66 5.5  5.36 5.22 5.09 4.97 4.85 4.74 4.63\n",
      " 4.53 4.43 4.34 4.25 4.16 4.08 4.   3.92 3.85 3.77 3.71 3.64 3.58 3.51], \n",
      "i4pirdz: [5.46 5.29 5.13 4.98 4.84 4.7  4.57 4.45 4.34 4.23 4.13 4.03 3.94 3.85\n",
      " 3.76 3.68 3.6  3.53 3.46 3.39 3.32 3.26 3.2  3.14 3.08 3.03 2.97 2.92], \n",
      "r: [0.61 0.63 0.65 0.67 0.69 0.71 0.73 0.75 0.77 0.79 0.81 0.83 0.85 0.87\n",
      " 0.89 0.91 0.93 0.95 0.97 0.99 1.01 1.03 1.05 1.07 1.09 1.11 1.13 1.15], \n",
      "dr: 0.019740700721740723, \n",
      "dz: 0.023750007152557373\n",
      "df: (26382, 63, 28), df[0,0,:]: [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0. -0. -0. -0. -0. -0.]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Br values mismatch: 0.48181259632110596",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[37]\u001b[39m\u001b[32m, line 66\u001b[39m\n\u001b[32m     64\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m Bz2.shape == vals[BZ].shape, \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mBz shape mismatch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mBz2.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m != \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvals[BZ].shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m     65\u001b[39m \u001b[38;5;66;03m# check the values\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m66\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m np.allclose(Br2, vals[BR], atol=\u001b[32m1e-5\u001b[39m), \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mBr values mismatch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp.max(np.abs(Br2\u001b[38;5;250m \u001b[39m-\u001b[38;5;250m \u001b[39mvals[BR]))\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m     67\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m np.allclose(Bz2, vals[BZ], atol=\u001b[32m1e-5\u001b[39m), \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mBz values mismatch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp.max(np.abs(Bz2\u001b[38;5;250m \u001b[39m-\u001b[38;5;250m \u001b[39mvals[BZ]))\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m     70\u001b[39m Y = [  \n\u001b[32m     71\u001b[39m     vals[FX], \n\u001b[32m     72\u001b[39m     vals[IY], \n\u001b[32m   (...)\u001b[39m\u001b[32m     75\u001b[39m     np.concatenate([vals[RQ], vals[ZQ]], axis=\u001b[32m1\u001b[39m) \n\u001b[32m     76\u001b[39m ]\n",
      "\u001b[31mAssertionError\u001b[39m: Br values mismatch: 0.48181259632110596"
     ]
    }
   ],
   "source": [
    "# load the data\n",
    "print(\"Loading data...\")\n",
    "\n",
    "# list all the files inside RAW_DIR/ds\n",
    "files = sorted([f for f in os.listdir(RAW_DIR) if f.endswith('.mat')])\n",
    "print(f'Found {len(files)} files.')\n",
    "vals = {n:[] for n in DS_NAMES}  # dictionary to hold the numpy arrays\n",
    "files_iter = tqdm(files, desc=\"Loading files\", unit=\"file\") if LOCAL else files\n",
    "for f in files_iter:\n",
    "    try:\n",
    "    # if True:\n",
    "        d = loadmat(join(RAW_DIR, f))\n",
    "        for n in DS_NAMES: assert n in list(d.keys()), f'Key {n} not found in {f}' \n",
    "        t = d['t'].flatten()  # time\n",
    "        nt = t.shape[0]  # number of time points\n",
    "        for n in DS_NAMES:\n",
    "            v = d[n] # get the variable\n",
    "            v = v.reshape((*DS_SIZES[n], nt)) # try to reshape it to the expected shape\n",
    "            assert v.shape == (*DS_SIZES[n], nt), f'Variable {n} shape mismatch: {v.shape} != {((*DS_SIZES[n], nt))}'\n",
    "            assert not np.isnan(v).any(), f'Variable {n} contains NaN values in {f}'\n",
    "            assert np.isfinite(v).all(), f'Variable {n} contains infinite values in {f}'\n",
    "            vals[n].append(v)  # append to the list\n",
    "    except Exception as e:\n",
    "        print(f'Error loading {f}: {e}')\n",
    "        continue\n",
    "\n",
    "print(f'Loaded {len(vals[FX])} files.')\n",
    "assert len(vals[FX]) > 0, f'No samples: {len(vals[FX])}'\n",
    "\n",
    "# convert lists to numpy arrays\n",
    "print('---------------------------------------------------')\n",
    "for n in DS_NAMES:\n",
    "    vals[n] = np.concatenate(vals[n], axis=-1).astype(DTYPE)  # concatenate along the first dimension and convert to DTYPE\n",
    "    sh, ndim = vals[n].shape, vals[n].ndim\n",
    "    vals[n] = vals[n].transpose(ndim-1, *range(ndim-1))  # move the last dimension to the first\n",
    "    print(f'{n} -> shape: {vals[n].shape}, dtype: {vals[n].dtype}')  # print the shape and dtype of the variable\n",
    "print('---------------------------------------------------')\n",
    "\n",
    "for n in INPUT_NAMES: assert vals[n].ndim == 2, f'Variable {n} is not 2D: {vals[n].ndim}'\n",
    "\n",
    "# assign values to variables\n",
    "X = np.concatenate([vals[n] for n in INPUT_NAMES], axis=1)  # concatenate along the first dimension\n",
    "print(f'-----------------------------------------\\n X -> shape: {X.shape}, dtype: {X.dtype}')\n",
    "\n",
    "# make IY the same shape as FX (and pad the sides)\n",
    "tmpIy = np.zeros_like(vals[FX])  # create a zero array with the same shape as FX\n",
    "tmpIy[:, 1:-1, 1:-1] = vals[IY]  # fill the inner part with IY values\n",
    "# fill sides \n",
    "tmpIy[:, 0, 1:-1] = vals[IY][:, 0, :]  # left side\n",
    "tmpIy[:, -1, 1:-1] = vals[IY][:, -1, :]  # right side\n",
    "tmpIy[:, 1:-1, 0] = vals[IY][:, :, 0]  # top side\n",
    "tmpIy[:, 1:-1, -1] = vals[IY][:, :, -1]  # bottom side\n",
    "# corners\n",
    "tmpIy[:, 0, 0] = vals[IY][:, 0, 0]  # top left corner\n",
    "tmpIy[:, 0, -1] = vals[IY][:, 0, -1]  # top right corner\n",
    "tmpIy[:, -1, 0] = vals[IY][:, -1, 0]  # bottom left corner\n",
    "tmpIy[:, -1, -1] = vals[IY][:, -1, -1]  # bottom right corner\n",
    "vals[IY] = tmpIy  # replace IY with the new array\n",
    "\n",
    "# recalculate Br, Bz\n",
    "Br2, Bz2 = meqBrBz(vals[FX])  # calculate Br, Bz from FX\n",
    "# check the shapes\n",
    "assert Br2.shape == vals[BR].shape, f'Br shape mismatch: {Br2.shape} != {vals[BR].shape}'\n",
    "assert Bz2.shape == vals[BZ].shape, f'Bz shape mismatch: {Bz2.shape} != {vals[BZ].shape}'\n",
    "# check the values\n",
    "assert np.allclose(Br2, vals[BR], atol=1e-5), f'Br values mismatch: {np.max(np.abs(Br2 - vals[BR]))}'\n",
    "assert np.allclose(Bz2, vals[BZ], atol=1e-5), f'Bz values mismatch: {np.max(np.abs(Bz2 - vals[BZ]))}'\n",
    "\n",
    "\n",
    "Y = [  \n",
    "    vals[FX], \n",
    "    vals[IY], \n",
    "    vals[BR],\n",
    "    vals[BZ],\n",
    "    np.concatenate([vals[RQ], vals[ZQ]], axis=1) \n",
    "]\n",
    "\n",
    "\n",
    "assert Y[0].shape[0] > 0, f'No samples: {Y[0].shape}'\n",
    "N_OR = Y[0].shape[0]  # number of original samples\n",
    "print(f'Loaded {N_OR} samples.')\n",
    "\n",
    "assert X.dtype == DTYPE, f'X dtype mismatch: {X.dtype} != {DTYPE}'\n",
    "assert all(y.dtype == DTYPE for y in Y), f'Y dtype mismatch: {[y.dtype for y in Y]} != s{DTYPE}'\n",
    "\n",
    "assert X.shape == (N_OR, NIN), f'X shape mismatch: {X.shape} != ({N_OR}, {NIN})'\n",
    "\n",
    "# check the shapes\n",
    "print(f'X -> {X.shape}')\n",
    "print(f'Y -> {[y.shape for y in Y]}')\n",
    "\n",
    "# print sizes in MB\n",
    "print(f'X size: {X.nbytes / 1024**2:.2f} MB, Y size: {sum([y.nbytes for y in Y]) / 1024**2:.2f} MB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot some examples\n",
    "n_plot = 3 if LOCAL else 15\n",
    "rand_idxs = np.random.randint(0, N_OR, n_plot)\n",
    "for i, ri in enumerate(rand_idxs):\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    plt.subplot(2, 4, 1)\n",
    "    plt.scatter(RRD, ZZD, c=vals[FX][ri], s=4), plt.title('FX')\n",
    "    plt.plot(vals[RQ][ri], vals[ZQ][ri], 'gray', lw=2)\n",
    "    plot_vessel(), plt.axis('equal'), plt.axis('off'), plt.colorbar()\n",
    "    plt.subplot(2, 4, 2)\n",
    "    plt.scatter(RRD, ZZD, c=vals[IY][ri], s=4), plt.title('IY')\n",
    "    plt.plot(vals[RQ][ri], vals[ZQ][ri], 'gray', lw=2)\n",
    "    plot_vessel(), plt.axis('equal'), plt.axis('off'), plt.colorbar()\n",
    "    plt.subplot(2, 4, 3)\n",
    "    plt.scatter(RRD, ZZD, c=vals[BR][ri], s=4), plt.title('BR')\n",
    "    plt.plot(vals[RQ][ri], vals[ZQ][ri], 'gray', lw=2)\n",
    "    plot_vessel(), plt.axis('equal'), plt.axis('off'), plt.colorbar()\n",
    "    plt.subplot(2, 4, 4)\n",
    "    plt.scatter(RRD, ZZD, c=vals[BZ][ri], s=4), plt.title('BZ')\n",
    "    plt.plot(vals[RQ][ri], vals[ZQ][ri], 'gray', lw=2)\n",
    "    plot_vessel(), plt.axis('equal'), plt.axis('off'), plt.colorbar()\n",
    "    plt.subplot(2, 4, 5)\n",
    "    plt.bar(np.arange(vals[BM].shape[1]), vals[BM][ri]), plt.title('BM')\n",
    "    plt.subplot(2, 4, 6)\n",
    "    plt.bar(np.arange(vals[FF].shape[1]), vals[FF][ri]), plt.title('FF')\n",
    "    plt.subplot(2, 4, 7)\n",
    "    plt.bar(np.arange(vals[IA].shape[1]), vals[IA][ri]), plt.title('IA')\n",
    "    plt.subplot(2, 4, 8)\n",
    "    plt.bar(np.arange(vals[IU].shape[1]), vals[IU][ri]), plt.title('IU')\n",
    "    plt.tight_layout()\n",
    "    plt.suptitle(f'SHOT {ri}')\n",
    "    plt.show() if LOCAL else plt.savefig(f'{DS_DIR}/imgs/original_{i}.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test interpolation\n",
    "idx = np.random.randint(0, N_OR)\n",
    "f, rhs = Y1[idx,:,:], Y2[idx,:,:]\n",
    "rrg, zzg = sample_random_subgrid(RRD,ZZD, NGZ, NGR)\n",
    "print(f.shape, rhs.shape, rrg.shape, zzg.shape)\n",
    "box = grid2box(rrg, zzg)\n",
    "f_grid = interp_fun(vals[FX][idx,:,:], RRD, ZZD, rrg, zzg)\n",
    "rhs_grid = interp_fun(rhs, RRD, ZZD, rrg, zzg)\n",
    "\n",
    "fig,ax = plt.subplots(1,5, figsize=(20,5))\n",
    "ax[0].scatter(RRD, ZZD, marker='.')\n",
    "ax[0].scatter(rrg, zzg, marker='.')\n",
    "plot_vessel(ax[0])\n",
    "ax[0].set_aspect('equal')\n",
    "\n",
    "# im1 = ax[1].contourf(RRD, ZZD, f, 20)\n",
    "im1 = ax[1].scatter(RRD, ZZD, c=f.flatten(), s=4)\n",
    "ax[1].plot(box[:,0],box[:,1])\n",
    "plot_vessel(ax[1])\n",
    "ax[1].set_aspect('equal')\n",
    "\n",
    "# im2 = ax[2].contourf(rrg, zzg, f_grid, 20)\n",
    "im2 = ax[2].scatter(rrg, zzg, c=f_grid.flatten(), s=4)\n",
    "plot_vessel(ax[2])\n",
    "ax[2].set_aspect('equal')\n",
    "\n",
    "# im3 = ax[3].contourf(RRD, ZZD, rhs, 20)\n",
    "im3 = ax[3].scatter(RRD, ZZD, c=rhs.flatten(), s=4)\n",
    "ax[3].set_aspect('equal')\n",
    "ax[3].plot(box[:,0],box[:,1])\n",
    "plot_vessel(ax[3])\n",
    "\n",
    "# im4 = ax[4].contourf(rrg, zzg, rhs_grid, 20)\n",
    "im4 = ax[4].scatter(rrg, zzg, c=rhs_grid.flatten(), s=4)\n",
    "plot_vessel(ax[4])\n",
    "ax[4].set_aspect('equal')\n",
    "\n",
    "plt.colorbar(im1,ax=ax[1])\n",
    "plt.colorbar(im2,ax=ax[2])\n",
    "plt.colorbar(im3,ax=ax[3])\n",
    "plt.colorbar(im4,ax=ax[4])\n",
    "\n",
    "plt.show() if LOCAL else plt.savefig(join(DS_DIR, 'imgs', 'interpolation_example.png'))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset splitting (N_TOP = original dataset size)\n",
    "NT = int(N_SAMPLES*TRAIN_EVAL_SPLIT)    # training\n",
    "NE = N_SAMPLES - NT                     # evaluation\n",
    "NTM, NEM = NT*SM, NE*SM # training and evaluation with multiple grids\n",
    "print(f\"Train -> NT:{NT} NTM:{NTM}\")\n",
    "print(f\"Eval  -> NE:{NE} NEM:{NEM}\")\n",
    "orig_idxs = np.random.permutation(N_OR)\n",
    "orig_idxs_train = orig_idxs[:int(N_OR*TRAIN_EVAL_SPLIT)] # original indices for training\n",
    "orig_idxs_eval = orig_idxs[int(N_OR*TRAIN_EVAL_SPLIT):] # original indices for evaluation\n",
    "# splitting the idxs\n",
    "assert len(orig_idxs_train) > NT, f\"Training set is too small, {len(orig_idxs_train)} < {NT}\"\n",
    "idxs_t = np.random.choice(orig_idxs_train, NT, replace=False) # can overlap with idxs_tf\n",
    "assert len(orig_idxs_eval) > NE, f\"Evaluation set is too small, {len(orig_idxs_eval)} < {NE}\"\n",
    "idxs_e = np.random.choice(orig_idxs_eval, NE, replace=False) # can overlap with idxs_ef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create arrays to store the dataset\n",
    "print(f\"Preallocating arrays for the dataset...\")\n",
    "\n",
    "xt =   np.zeros((NTM, NIN), dtype=DTYPE)\n",
    "y1t =  np.zeros((NTM, NGZ, NGR), dtype=DTYPE)\n",
    "y2t =  np.zeros((NTM, NGZ, NGR), dtype=DTYPE)\n",
    "y3t =  np.zeros((NTM, 2*NLCFS), dtype=DTYPE)\n",
    "rt =   np.zeros((NTM, NGR), dtype=DTYPE)\n",
    "zt =   np.zeros((NTM, NGZ), dtype=DTYPE)\n",
    "\n",
    "xe =   np.zeros((NEM, NIN), dtype=DTYPE)\n",
    "y1e =  np.zeros((NEM, NGZ, NGR), dtype=DTYPE)\n",
    "y2e =  np.zeros((NEM, NGZ, NGR), dtype=DTYPE)\n",
    "y3e =  np.zeros((NEM, 2*NLCFS), dtype=DTYPE)\n",
    "re =   np.zeros((NEM, NGR), dtype=DTYPE)\n",
    "ze =   np.zeros((NEM, NGZ), dtype=DTYPE)\n",
    "\n",
    "# estimate RAM usage\n",
    "ram_usage = sum(arr.nbytes for arr in [xt, y1t, y2t, y3t, rt, zt, xe, y1e, y2e, y3e, re, ze]) / 1024**3 \n",
    "print(f\"Estimated RAM usage: {ram_usage:.2f} GB\\nFilling arrays...\")\n",
    "\n",
    "## fill the arrays\n",
    "print_every = 2000\n",
    "start_time = time()\n",
    "for i, idx in enumerate(idxs_t):\n",
    "    rrs, zzs = np.zeros((SM,NGZ,NGR), dtype=DTYPE), np.zeros((SM,NGZ,NGR), dtype=DTYPE)\n",
    "    for j in range(SM): rrs[j], zzs[j] = sample_random_subgrid(RRD,ZZD,NGZ,NGR)\n",
    "    si, ei = i*SM, (i+1)*SM # start and end idxs\n",
    "    xt[si:ei] = X[idx]\n",
    "    y1t[si:ei] = interp_fun(Y1[idx], RRD, ZZD, rrs, zzs)\n",
    "    y2t[si:ei] = interp_fun(Y2[idx], RRD, ZZD, rrs, zzs)\n",
    "    y3t[si:ei] = Y3[idx]\n",
    "    rt[si:ei], zt[si:ei] = rrs[:,0,:], zzs[:,:,0] # save only the first raw/col\n",
    "    if (i+1) % print_every == 0: print(f\"Train -> {100*(i+1)*SM/NTM:.1f}%, eta: {((time()-start_time)/(i+1)*(NT-i-1))/60:.1f} min\")\n",
    "\n",
    "start_time = time()\n",
    "for i, idx in enumerate(idxs_e):\n",
    "    rrs, zzs = np.zeros((SM,NGZ,NGR), dtype=DTYPE), np.zeros((SM,NGZ,NGR), dtype=DTYPE)\n",
    "    for j in range(SM): rrs[j], zzs[j] = sample_random_subgrid(RRD,ZZD,NGZ,NGR)\n",
    "    si, ei = i*SM, (i+1)*SM # start and end idxs\n",
    "    xe[si:ei] = X[idx]\n",
    "    y1e[si:ei] = interp_fun(Y1[idx], RRD, ZZD, rrs, zzs)\n",
    "    y2e[si:ei] = interp_fun(Y2[idx], RRD, ZZD, rrs, zzs)\n",
    "    y3e[si:ei] = Y3[idx]\n",
    "    re[si:ei], ze[si:ei] = rrs[:,0,:], zzs[:,:,0] # save only the first raw/col\n",
    "    if (i+1) % print_every == 0: print(f\"Eval -> {100*(i+1)*SM/NEM:.1f}%, eta: {((time()-start_time)/(i+1)*(NE-i-1))/60:.1f} min\")\n",
    "\n",
    "print(f\"xt: {xt.shape}, y1t: {y1t.shape}, y2t: {y2t.shape}, y3t: {y3t.shape}, rt: {rt.shape}, zt: {zt.shape}\")\n",
    "print(f\"xe: {xe.shape}, y1e: {y1e.shape}, y2e: {y2e.shape}, y3e: {y3e.shape}, re: {re.shape}, ze: {ze.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate kernels for Grad-Shafranov equation # NOTE: not needed actually, but here to be tested\n",
    "# so we don't have to do it during training\n",
    "print(\"Calculating kernels...\")\n",
    "laplace_ker_t = np.zeros((len(xt[0]), 3, 3), dtype=DTYPE)\n",
    "laplace_ker_e = np.zeros((len(xe[0]), 3, 3), dtype=DTYPE)\n",
    "df_dr_ker_t = np.zeros((len(xt[0]), 3, 3), dtype=DTYPE)\n",
    "df_dr_ker_e = np.zeros((len(xe[0]), 3, 3), dtype=DTYPE)\n",
    "# hrs_t, hzs_t = rt[:,1,2]-rt[:,1,1], zt[:,2,1]-zt[:,1,1]\n",
    "# hrs_e, hzs_e = re[:,1,2]-re[:,1,1], ze[:,2,1]-ze[:,1,1]\n",
    "hrs_e, hzs_e = re[:,2]-re[:,1], ze[:,2]-ze[:,1]\n",
    "hrs_t, hzs_t = rt[:,2]-rt[:,1], zt[:,2]-zt[:,1]\n",
    "for i in range(len(xt[0])):\n",
    "    try:\n",
    "        laplace_ker_t[i,:,:], df_dr_ker_t[i,:,:] = calc_laplace_df_dr_ker(hrs_t[i], hzs_t[i])\n",
    "    except Exception as e:\n",
    "        print(f\"Error calculating laplace_ker_t for index {i}: {e}\")\n",
    "        plt.figure()\n",
    "        plt.scatter(rt[i], zt[i], marker='.')\n",
    "        plt.title(f\"rt[{i}]\")\n",
    "        plt.axis('equal')\n",
    "        plt.show() if LOCAL else plt.savefig(f'{DS_DIR}/imgs/rr_train_{i}.png')\n",
    "        plt.close()\n",
    "        break\n",
    "\n",
    "for i in range(len(xe[0])):\n",
    "    laplace_ker_e[i,:,:], df_dr_ker_e[i,:,:] = calc_laplace_df_dr_ker(hrs_e[i], hzs_e[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the dataset\n",
    "print(\"Checking the dataset...\")\n",
    "rows = 5\n",
    "idxs_train = np.random.randint(0, len(xt[0]), rows)\n",
    "idxs_eval = np.random.randint(0, len(xe[0]), rows)\n",
    "fig,ax = plt.subplots(rows,6, figsize=(20,4*rows))\n",
    "box0 = grid2box(RRD, ZZD)\n",
    "for i, (it, ie)  in enumerate(zip(idxs_train, idxs_eval)):\n",
    "    # training\n",
    "    boxi = grid2box(rt[it], zt[it])\n",
    "    ax[i,0].plot(box0[:,0], box0[:,1])\n",
    "    ax[i,0].plot(boxi[:,0], boxi[:,1])\n",
    "    ax[i,0].set_aspect('equal')\n",
    "    ax[i,0].set_title(f\"Train {it}\")\n",
    "    a1 = ax[i,1].contourf(rt[it], zt[it], y1t[it], 20)\n",
    "    ax[i,1].plot(box0[:,0], box0[:,1])\n",
    "    ax[i,1].plot(y3t[it,:NLCFS], y3t[it,NLCFS:], 'gray', lw=2)\n",
    "    ax[i,1].set_aspect('equal')\n",
    "    plt.colorbar(a1,ax=ax[i,1])\n",
    "    a2 = ax[i,2].contourf(rt[it], zt[it], y2t[it], 20)\n",
    "    ax[i,2].plot(box0[:,0], box0[:,1])\n",
    "    ax[i,2].set_aspect('equal')\n",
    "    plt.colorbar(a2,ax=ax[i,2])\n",
    "    # evaluation\n",
    "    boxi = grid2box(re[ie], ze[ie])\n",
    "    ax[i,3].plot(box0[:,0], box0[:,1])\n",
    "    ax[i,3].plot(boxi[:,0], boxi[:,1])\n",
    "    ax[i,3].set_aspect('equal')\n",
    "    ax[i,3].set_title(f\"Eval {ie}\")\n",
    "    a1 = ax[i,4].contourf(re[ie], ze[ie], y1e[ie], 20)\n",
    "    ax[i,4].plot(box0[:,0], box0[:,1])\n",
    "    ax[i,4].plot(y3e[ie,:NLCFS], y3e[ie,NLCFS:], 'gray', lw=2)\n",
    "    ax[i,4].set_aspect('equal')\n",
    "    plt.colorbar(a1,ax=ax[i,4])\n",
    "    a2 = ax[i,5].contourf(re[ie], ze[ie], y2e[ie], 20)\n",
    "    ax[i,5].plot(box0[:,0], box0[:,1])\n",
    "    ax[i,5].set_aspect('equal')\n",
    "    plt.colorbar(a2,ax=ax[i,5])\n",
    "plt.show() if LOCAL else plt.savefig(join(DS_DIR, 'imgs', 'dataset_check.png'))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import calc_gso, calc_gso_batch\n",
    "import torch\n",
    "print(\"Checking the Grad-Shafranov operator...\")\n",
    "n_plots = 7\n",
    "idxs = np.random.randint(0, len(xt[0]), n_plots)\n",
    "psis, rhss = y1t[idxs], y2t[idxs]\n",
    "rs, zs = rt[idxs], zt[idxs]\n",
    "big_box = grid2box(RRD, ZZD)\n",
    "#batched version\n",
    "psist = torch.tensor(psis, dtype=torch.float32).view(n_plots, 1, NGZ, NGR)\n",
    "rst = torch.tensor(rs, dtype=torch.float32).view(n_plots, NGR)\n",
    "zst = torch.tensor(zs, dtype=torch.float32).view(n_plots, NGZ)\n",
    "print(f'psi: {psist.shape}, r: {rst.shape}, z: {zst.shape}')\n",
    "gsos = calc_gso_batch(psist, rst, zst)\n",
    "print(f'gsos: {gsos.shape}')\n",
    "gsos = gsos.view(n_plots, NGZ, NGR).numpy()\n",
    "# single version\n",
    "for i in range(n_plots):\n",
    "    psi, r, z, rhs = psis[i], rs[i], zs[i], rhss[i]\n",
    "    box = grid2box(r, z)\n",
    "    gso = calc_gso(psi, r, z) # calculate the Grad-Shafranov operator\n",
    "    gso2 = gsos[i]\n",
    "    #plot error gso vs gso2\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "    rr, zz = np.meshgrid(r, z)\n",
    "    im = ax.contourf(rr, zz, np.abs(gso-gso2), 20)\n",
    "    ax.plot(big_box[:,0], big_box[:,1])\n",
    "    ax.set_aspect('equal')\n",
    "    ax.set_title(f\"Error batch/no batch {i}\")\n",
    "    plt.colorbar(im, ax=ax)\n",
    "    plt.show() if LOCAL else plt.savefig(join(DS_DIR, 'imgs', f'gso_error_{i}.png'))\n",
    "    plt.close()\n",
    "    # NOTE: the error between the batched and non-batched version can be non-zero due to different\n",
    "    # implementations in gpu\n",
    "    print(f\"max error batch/no batch: {np.abs(gso-gso2).max()}\")\n",
    "    # assert np.allclose(gso, gso2, rtol=1e-2), f\"Error in the calculation of the Grad-Shafranov operator: \\ngso:\\n{gso}, \\ngso2:\\n{gso2}\"\n",
    "    # psi, gso, rhs = psi[1:-1,1:-1], gso[1:-1,1:-1], rhs[1:-1,1:-1]\n",
    "    # rr, zz = rr[1:-1,1:-1], zz[1:-1,1:-1] \n",
    "    fig,ax = plt.subplots(1,5, figsize=(20,5))\n",
    "    ax[0].plot(big_box[:,0], big_box[:,1])\n",
    "    ax[0].plot(box[:,0], box[:,1])\n",
    "    ax[0].set_aspect('equal')\n",
    "    ax[0].set_xticks([]), ax[0].set_yticks([])\n",
    "    ax[0].set_title(f\"Train {idxs}\")\n",
    "    im1 = ax[1].contourf(rr, zz, psi, 20)\n",
    "    ax[1].plot(big_box[:,0], big_box[:,1])\n",
    "    ax[1].set_aspect('equal')\n",
    "    ax[1].set_xticks([]), ax[1].set_yticks([])\n",
    "    ax[1].set_title(\"Ψ\")\n",
    "    im2 = ax[2].contourf(rr, zz, -gso, 20)\n",
    "    ax[2].plot(big_box[:,0], big_box[:,1])\n",
    "    ax[2].set_aspect('equal')\n",
    "    ax[2].set_xticks([]), ax[2].set_yticks([])\n",
    "    ax[2].set_title(\"GSO recalculated\")\n",
    "    im3 = ax[3].contourf(rr, zz, -rhs, 20)\n",
    "    ax[3].plot(big_box[:,0], big_box[:,1])\n",
    "    ax[3].set_aspect('equal')\n",
    "    ax[3].set_xticks([]), ax[3].set_yticks([])\n",
    "    ax[3].set_title(\"GSO from dataset\")\n",
    "    im4 = ax[4].contourf(rr, zz, np.abs(gso-rhs), 20)\n",
    "    ax[4].plot(big_box[:,0], big_box[:,1])\n",
    "    ax[4].set_aspect('equal')\n",
    "    ax[4].set_xticks([]), ax[4].set_yticks([])\n",
    "    ax[4].set_title(\"Absolute error\")\n",
    "    plt.colorbar(im1,ax=ax[1])\n",
    "    plt.colorbar(im2,ax=ax[2])\n",
    "    plt.colorbar(im3,ax=ax[3])\n",
    "    plt.colorbar(im4,ax=ax[4])\n",
    "    plt.show() if LOCAL else plt.savefig(join(DS_DIR, 'imgs', f'gso_check_{i}.png'))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert y1t.shape[1:] == (NGR, NGZ), f\"xt shape mismatch: {xt[0].shape[1:]} != ({NGR}, {NGZ})\"\n",
    "assert y1e.shape[1:] == (NGR, NGZ), f\"xe shape mismatch: {xe[0].shape[1:]} != ({NGR}, {NGZ})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset and normalize, NOTE: y3 does not require normalization\n",
    "print(\"Normalizing the dataset...\")\n",
    "μx, Σx = np.mean(xt, axis=0), np.std(xt, axis=0)\n",
    "# μy1, Σy1 = np.mean(y1t, axis=0), np.std(y1t, axis=0)\n",
    "# μy2, Σy2 = np.mean(y2t, axis=0), np.std(y2t, axis=0)\n",
    "μy1, Σy1 = np.mean(y1t), np.std(y1t)\n",
    "μy2, Σy2 = np.mean(y2t), np.std(y2t)\n",
    "\n",
    "# normalize (NOTE: both with the training means and stds)\n",
    "# xt, xe = (xt - μx) / Σx, (xe - μx) / Σx # not normalizing the inputs bc we added a normalization layer in the network architecture\n",
    "y1t, y1e = (y1t - μy1) / Σy1, (y1e - μy1) / Σy1\n",
    "y2t, y2e = (y2t - μy2) / Σy2, (y2e - μy2) / Σy2\n",
    "\n",
    "print(f'μx: {μx.shape}, Σx: {Σx.shape}')\n",
    "print(f'μy1: {μy1.shape}, Σy1: {Σy1.shape}')\n",
    "print(f'μy2: {μy2.shape}, Σy2: {Σy2.shape}')\n",
    "\n",
    "x_mean_std = np.array([μx, Σx])\n",
    "y1_mean_std = np.array([μy1, Σy1])\n",
    "y2_mean_std = np.array([μy2, Σy2])\n",
    "\n",
    "print(f'x_mean_std: {x_mean_std.shape}')\n",
    "print(f'y1_mean_std: {y1_mean_std.shape}')  \n",
    "print(f'y2_mean_std: {y2_mean_std.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dataset as numpy compressed\n",
    "print(f\"Saving datasets to {TRAIN_DS_PATH} and {EVAL_DS_PATH}...\")\n",
    "try:\n",
    "    np.savez_compressed(TRAIN_DS_PATH, X=xt, Y1=y1t, Y2=y2t, Y3=y3t, r=rt, z=zt, x_mean_std=x_mean_std, y1_mean_std=y1_mean_std, y2_mean_std=y2_mean_std)\n",
    "    np.savez_compressed(EVAL_DS_PATH, X=xe, Y1=y1e, Y2=y2e, Y3=y3e, r=re, z=ze, x_mean_std=x_mean_std, y1_mean_std=y1_mean_std, y2_mean_std=y2_mean_std)\n",
    "except Exception as e:\n",
    "    print(f\"Error saving datasets: {e}\")\n",
    "    raise e\n",
    "print(f\"Datasets saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save a .mat demo file for testing\n",
    "print(f\"Saving demo file to {DS_DIR}/demo.mat and {DS_DIR}/demo.npz\")\n",
    "rand_idxs = np.random.randint(0, len(xe), 100)\n",
    "demo = {'X': xe[rand_idxs], 'Y': y3e[rand_idxs]}\n",
    "try:\n",
    "    savemat(join(DS_DIR, 'demo.mat'), demo)\n",
    "    np.savez_compressed(join(DS_DIR, 'demo.npz'), X=xe[rand_idxs], Y=y3e[rand_idxs])\n",
    "except Exception as e:\n",
    "    print(f\"Error saving demo file: {e}\")\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot some examples\n",
    "print(\"Testing the dataset...\")\n",
    "tds, eds = np.load(TRAIN_DS_PATH), np.load(EVAL_DS_PATH)\n",
    "print(f'train_ds: {tds.keys()}')\n",
    "print(f'eval_ds: {eds.keys()}')\n",
    "# plot some examples\n",
    "rs, zs, xs, y1s, y2s, y3s = tds['r'], tds['z'], tds['X'], tds['Y1'], tds['Y2'], tds['Y3']\n",
    "xs = (xs - μx) / Σx # normalize the inputs\n",
    "print(f'rs shape: {rs.shape}, zs shape: {zs.shape}, xs shape: {xs.shape}, y1s shape: {y1s.shape}, y2s shape: {y2s.shape}, y3s shape: {y3s.shape}')\n",
    "\n",
    "n_plot = 3 if LOCAL else 100\n",
    "rand_idxs = np.random.randint(0, NT, n_plot)\n",
    "for i, ri in enumerate(rand_idxs):\n",
    "    r, z, x, y1, y2, y3 = rs[ri], zs[ri], xs[ri], y1s[ri], y2s[ri], y3s[ri]\n",
    "    rr, zz = np.meshgrid(r, z)\n",
    "    plt.figure(figsize=(16, 4))\n",
    "    plt.subplot(1, 5, 1)\n",
    "    # plt.contourf(rr, zz, y1, levels=20)\n",
    "    plt.scatter(rr, zz, c=y1.flatten(), marker='.')\n",
    "    plt.plot(y3[:NLCFS], y3[NLCFS:], 'gray', lw=2)\n",
    "    plot_vessel()\n",
    "    plt.axis('equal'), plt.axis('off')\n",
    "    plt.title('Y1')\n",
    "    plt.colorbar()\n",
    "    plt.subplot(1, 5, 2)\n",
    "    # plt.contourf(rr, zz, y2, levels=20)\n",
    "    plt.scatter(rr, zz, c=y2.flatten(), marker='.')\n",
    "    plt.plot(y3[:NLCFS], y3[NLCFS:], 'gray', lw=2)\n",
    "    plot_vessel()\n",
    "    plt.axis('equal'), plt.axis('off')\n",
    "    plt.title('Y2')\n",
    "    plt.colorbar()\n",
    "    plt.subplot(1, 5, (3,5))\n",
    "    plt.bar(np.arange(x.shape[0]), x)\n",
    "    plt.title('X')\n",
    "    plt.tight_layout()\n",
    "    plt.suptitle(f'SHOT {ri} (inputs normalized)')\n",
    "    plt.show() if LOCAL else plt.savefig(f'{DS_DIR}/imgs/ds_{i}.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Done! Space used:')\n",
    "os.system(f'du -h {TRAIN_DS_PATH}')\n",
    "os.system(f'du -h {EVAL_DS_PATH}')\n",
    "assert os.path.exists(TRAIN_DS_PATH), f\"Dataset not saved: {TRAIN_DS_PATH}\"\n",
    "assert os.path.exists(EVAL_DS_PATH), f\"Dataset not saved: {EVAL_DS_PATH}\"\n",
    "print(f\"{JOBID} done\")\n",
    "if not LOCAL: sleep(30) # wait for files to update (for cluster)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
