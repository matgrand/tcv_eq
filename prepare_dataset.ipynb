{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the training dataset from the equilibria dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing data...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\" # disable GPU\n",
    "import numpy as np\n",
    "from scipy.io import loadmat, savemat\n",
    "from time import time\n",
    "from os.path import join, exists\n",
    "from utils import *\n",
    "from tqdm import tqdm\n",
    "print(\"Preparing data...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "# HAS_SCREEN = True # prototypying\n",
    "HAS_SCREEN = False # for cluster\n",
    "DTYPE = 'float32'\n",
    "# TAR_GZ_FILE = 'dss/ds1.tar.gz' # the tar.gz file containing the data\n",
    "# TAR_GZ_FILE = 'dss/ds3.tar.gz' # the tar.gz file containing the data\n",
    "TAR_GZ_FILE = 'dss/ds5.tar.gz' # the tar.gz file containing the data\n",
    "TMP_DIR = 'dss/tmp' # where the data will be stored\n",
    "DATA_DIR = 'dss/ds' # where the data will be stored\n",
    "\n",
    "# hyperparameters\n",
    "N_SAMPLES = 200_000 #100_000 # number of samples to use for training\n",
    "TRAIN_EVAL_SPLIT = 0.8 # percentage of the dataset to use for training\n",
    "FULL_SUBGRID_SPLIT = 0.0 #0.25 # percentage of the full grid \n",
    "assert FULL_SUBGRID_SPLIT == 0.0, \"Full subgrid split must be zero\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the tar.gz file into the tmp directory\n",
    "if exists(TMP_DIR):\n",
    "    print(f\"Removing {TMP_DIR}...\")\n",
    "    os.system(f\"rm -rf {TMP_DIR}\")\n",
    "os.mkdir(TMP_DIR)\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "print(f\"Extracting {TAR_GZ_FILE} into {TMP_DIR}...\")\n",
    "os.system(f\"tar -xzf {TAR_GZ_FILE} -C {TMP_DIR}\")\n",
    "print(f\"Extracted {TAR_GZ_FILE} into {TMP_DIR}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RRD shape: (65, 28), ZZD shape: (65, 28)\n"
     ]
    }
   ],
   "source": [
    "# read the grid coordinates\n",
    "d = loadmat('tcv_params/grid.mat')\n",
    "RD, ZD = d['r'].flatten(), d['z'].flatten() # original grid coordinates (DATA)\n",
    "r0, r1 = RD[0], RD[-1]  # min and max r\n",
    "z0, z1 = ZD[0], ZD[-1]  # min and max z\n",
    "r,z = np.linspace(r0, r1, N_GRID_R), np.linspace(z0, z1, N_GRID_Z)  # grid coordinates\n",
    "\n",
    "RRD, ZZD = np.meshgrid(RD, ZD)  # meshgrid for the original grid coordinates (from the data)\n",
    "print(f'RRD shape: {RRD.shape}, ZZD shape: {ZZD.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'dss/tmp/ds'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mLoading data...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# list all the files inside TMP_DIR/ds\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m files = \u001b[38;5;28msorted\u001b[39m([f \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mTMP_DIR\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m/ds\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m f.endswith(\u001b[33m'\u001b[39m\u001b[33m.mat\u001b[39m\u001b[33m'\u001b[39m)])\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mFound \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(files)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m files.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      7\u001b[39m Fxs, Iys, Ias, Bms, Ufs = [], [], [], [], []\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'dss/tmp/ds'"
     ]
    }
   ],
   "source": [
    "# load the data\n",
    "print(\"Loading data...\")\n",
    "\n",
    "# list all the files inside TMP_DIR/ds\n",
    "files = sorted([f for f in os.listdir(f'{TMP_DIR}/ds') if f.endswith('.mat')])\n",
    "print(f'Found {len(files)} files.')\n",
    "Fxs, Iys, Ias, Bms, Ufs = [], [], [], [], []\n",
    "files_iter = tqdm(files, desc=\"Loading files\", unit=\"file\") if HAS_SCREEN else files\n",
    "# files_iter = files\n",
    "for f in files_iter:\n",
    "    try:\n",
    "    # if True:\n",
    "        d = loadmat(join(TMP_DIR, 'ds', f))\n",
    "        # print(f'file: {f}, keys: {d.keys()}') #  'Bm', 'Fx', 'Ia', 'Ip', 'Iy', 'Uf', 't'\n",
    "        t, Ip = d['t'].flatten(), d['Ip'].flatten()  # time and plasma current\n",
    "        sip = np.sign(np.mean(Ip)) # sign of the plasma current\n",
    "        Fx = d['Fx']  # flux map\n",
    "        Iy = d['Iy']  # current density map\n",
    "        Ia = d['Ia']  # coil currents\n",
    "        Bm = d['Bm']  # magnetic probe measurements\n",
    "        Uf = d['Uf']  # flux loop poloidal flux\n",
    "\n",
    "        nt = t.shape[0]  # number of time points\n",
    "        assert Fx.shape == (28, 65, nt), f'Fx shape mismatch: {Fx.shape} != (28, 65, {nt})'\n",
    "        assert Iy.shape == (28, 65, nt), f'Iy shape mismatch: {Iy.shape} != (28, 65, {nt})'\n",
    "        assert Ia.shape == (19, nt), f'Ia shape mismatch: {Ia.shape} != (19, {nt})'\n",
    "        assert Bm.shape == (38, nt), f'Bm shape mismatch: {Bm.shape} != (38, {nt})'\n",
    "        assert Uf.shape == (38, nt), f'Uf shape mismatch: {Uf.shape} != (38, {nt})'\n",
    "\n",
    "        # check none of the values are NaN\n",
    "        assert not np.isnan(Fx).any(), f'Fx contains NaN values: {f}'\n",
    "        assert not np.isnan(Iy).any(), f'Iy contains NaN values: {f}'\n",
    "        assert not np.isnan(Ia).any(), f'Ia contains NaN values: {f}'\n",
    "        assert not np.isnan(Bm).any(), f'Bm contains NaN values: {f}'\n",
    "        assert not np.isnan(Uf).any(), f'Uf contains NaN values: {f}'\n",
    "        # check the values are finite\n",
    "        assert np.isfinite(Fx).all(), f'Fx contains infinite values: {f}'\n",
    "        assert np.isfinite(Iy).all(), f'Iy contains infinite values: {f}'\n",
    "        assert np.isfinite(Ia).all(), f'Ia contains infinite values: {f}'\n",
    "        assert np.isfinite(Bm).all(), f'Bm contains infinite values: {f}'\n",
    "        assert np.isfinite(Uf).all(), f'Uf contains infinite values: {f}'\n",
    "    \n",
    "        Fxs.append(Fx), Iys.append(Iy), Ias.append(Ia), Bms.append(Bm), Ufs.append(Uf)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f'Error loading {f}: {e}')\n",
    "        continue\n",
    "\n",
    "print(f'Loaded {len(Fxs)} files.')\n",
    "assert len(Fxs) > 0, f'No samples: {len(Fxs)}'\n",
    "\n",
    "# convert to numpy arrays\n",
    "Fx = np.concatenate(Fxs, axis=-1).astype(DTYPE).transpose(2,1,0)  # flux map\n",
    "Iy = np.concatenate(Iys, axis=-1).astype(DTYPE).transpose(2,1,0)  # current density map\n",
    "Ia = np.concatenate(Ias, axis=-1).astype(DTYPE).transpose(1,0)  # coil currents\n",
    "Bm = np.concatenate(Bms, axis=-1).astype(DTYPE).transpose(1,0)  # magnetic probe measurements\n",
    "Uf = np.concatenate(Ufs, axis=-1).astype(DTYPE).transpose(1,0)  # flux loop poloidal flux\n",
    "\n",
    "assert Fx.shape[0] > 0, f'No samples: {Fx.shape}'\n",
    "\n",
    "N = Fx.shape[0]  # number of samples\n",
    "print(f'Loaded {N} samples.')\n",
    "\n",
    "# assign to standard values\n",
    "X = [Ia, Bm, Uf]  # inputs\n",
    "Y = Fx # outputs\n",
    "RHS = Iy  # right hand side\n",
    "\n",
    "# remove the tmp directory\n",
    "print(f\"Removing {TMP_DIR}...\")\n",
    "os.system(f\"rm -rf {TMP_DIR}\")\n",
    "print(\"Data loaded.\")\n",
    "\n",
    "# check the shapes\n",
    "print(f'Fx shape: {Fx.shape}, Iy shape: {Iy.shape}, Ia shape: {Ia.shape}, Bm shape: {Bm.shape}, Uf shape: {Uf.shape}')\n",
    "    \n",
    "# print sizes in MB\n",
    "print(f'Fx size: {Fx.nbytes / 1024**2:.2f} MB, Iy size: {Iy.nbytes / 1024**2:.2f} MB, Ia size: {Ia.nbytes / 1024**2:.2f} MB, Bm size: {Bm.nbytes / 1024**2:.2f} MB, Uf size: {Uf.nbytes / 1024**2:.2f} MB')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Shapes of x (65, 28) and z (28, 65) do not match",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m plt.figure(figsize=(\u001b[32m16\u001b[39m, \u001b[32m3\u001b[39m))\n\u001b[32m      6\u001b[39m plt.subplot(\u001b[32m1\u001b[39m, \u001b[32m5\u001b[39m, \u001b[32m1\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[43mplt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcontourf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRRD\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mZZD\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mFx\u001b[49m\u001b[43m[\u001b[49m\u001b[43mri\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevels\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m plt.axis(\u001b[33m'\u001b[39m\u001b[33mequal\u001b[39m\u001b[33m'\u001b[39m), plt.axis(\u001b[33m'\u001b[39m\u001b[33moff\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      9\u001b[39m plt.title(\u001b[33m'\u001b[39m\u001b[33mFx\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.13/site-packages/matplotlib/pyplot.py:3179\u001b[39m, in \u001b[36mcontourf\u001b[39m\u001b[34m(data, *args, **kwargs)\u001b[39m\n\u001b[32m   3177\u001b[39m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes.contourf)\n\u001b[32m   3178\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcontourf\u001b[39m(*args, data=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs) -> QuadContourSet:\n\u001b[32m-> \u001b[39m\u001b[32m3179\u001b[39m     __ret = \u001b[43mgca\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcontourf\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3180\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   3181\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3182\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m __ret._A \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m   3183\u001b[39m         sci(__ret)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.13/site-packages/matplotlib/__init__.py:1521\u001b[39m, in \u001b[36m_preprocess_data.<locals>.inner\u001b[39m\u001b[34m(ax, data, *args, **kwargs)\u001b[39m\n\u001b[32m   1518\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m   1519\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minner\u001b[39m(ax, *args, data=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m   1520\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1521\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1522\u001b[39m \u001b[43m            \u001b[49m\u001b[43max\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1523\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcbook\u001b[49m\u001b[43m.\u001b[49m\u001b[43msanitize_sequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1524\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcbook\u001b[49m\u001b[43m.\u001b[49m\u001b[43msanitize_sequence\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1526\u001b[39m     bound = new_sig.bind(ax, *args, **kwargs)\n\u001b[32m   1527\u001b[39m     auto_label = (bound.arguments.get(label_namer)\n\u001b[32m   1528\u001b[39m                   \u001b[38;5;129;01mor\u001b[39;00m bound.kwargs.get(label_namer))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.13/site-packages/matplotlib/axes/_axes.py:6791\u001b[39m, in \u001b[36mAxes.contourf\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   6780\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   6781\u001b[39m \u001b[33;03mPlot filled contours.\u001b[39;00m\n\u001b[32m   6782\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   6788\u001b[39m \u001b[33;03m%(contour_doc)s\u001b[39;00m\n\u001b[32m   6789\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   6790\u001b[39m kwargs[\u001b[33m'\u001b[39m\u001b[33mfilled\u001b[39m\u001b[33m'\u001b[39m] = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m6791\u001b[39m contours = \u001b[43mmcontour\u001b[49m\u001b[43m.\u001b[49m\u001b[43mQuadContourSet\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6792\u001b[39m \u001b[38;5;28mself\u001b[39m._request_autoscale_view()\n\u001b[32m   6793\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m contours\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.13/site-packages/matplotlib/contour.py:701\u001b[39m, in \u001b[36mContourSet.__init__\u001b[39m\u001b[34m(self, ax, levels, filled, linewidths, linestyles, hatches, alpha, origin, extent, cmap, colors, norm, vmin, vmax, colorizer, extend, antialiased, nchunk, locator, transform, negative_linestyles, clip_path, *args, **kwargs)\u001b[39m\n\u001b[32m    697\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.negative_linestyles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    698\u001b[39m     \u001b[38;5;28mself\u001b[39m.negative_linestyles = \\\n\u001b[32m    699\u001b[39m         mpl.rcParams[\u001b[33m'\u001b[39m\u001b[33mcontour.negative_linestyle\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m701\u001b[39m kwargs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_process_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    702\u001b[39m \u001b[38;5;28mself\u001b[39m._process_levels()\n\u001b[32m    704\u001b[39m \u001b[38;5;28mself\u001b[39m._extend_min = \u001b[38;5;28mself\u001b[39m.extend \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m'\u001b[39m\u001b[33mmin\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mboth\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.13/site-packages/matplotlib/contour.py:1319\u001b[39m, in \u001b[36mQuadContourSet._process_args\u001b[39m\u001b[34m(self, corner_mask, algorithm, *args, **kwargs)\u001b[39m\n\u001b[32m   1316\u001b[39m         corner_mask = mpl.rcParams[\u001b[33m'\u001b[39m\u001b[33mcontour.corner_mask\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m   1317\u001b[39m \u001b[38;5;28mself\u001b[39m._corner_mask = corner_mask\n\u001b[32m-> \u001b[39m\u001b[32m1319\u001b[39m x, y, z = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_contour_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1321\u001b[39m contour_generator = contourpy.contour_generator(\n\u001b[32m   1322\u001b[39m     x, y, z, name=\u001b[38;5;28mself\u001b[39m._algorithm, corner_mask=\u001b[38;5;28mself\u001b[39m._corner_mask,\n\u001b[32m   1323\u001b[39m     line_type=contourpy.LineType.SeparateCode,\n\u001b[32m   1324\u001b[39m     fill_type=contourpy.FillType.OuterCode,\n\u001b[32m   1325\u001b[39m     chunk_size=\u001b[38;5;28mself\u001b[39m.nchunk)\n\u001b[32m   1327\u001b[39m t = \u001b[38;5;28mself\u001b[39m.get_transform()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.13/site-packages/matplotlib/contour.py:1359\u001b[39m, in \u001b[36mQuadContourSet._contour_args\u001b[39m\u001b[34m(self, args, kwargs)\u001b[39m\n\u001b[32m   1357\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[32m2\u001b[39m < nargs <= \u001b[32m4\u001b[39m:\n\u001b[32m   1358\u001b[39m     x, y, z_orig, *args = args\n\u001b[32m-> \u001b[39m\u001b[32m1359\u001b[39m     x, y, z = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_check_xyz\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz_orig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1361\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1362\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m _api.nargs_error(fn, takes=\u001b[33m\"\u001b[39m\u001b[33mfrom 1 to 4\u001b[39m\u001b[33m\"\u001b[39m, given=nargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.13/site-packages/matplotlib/contour.py:1406\u001b[39m, in \u001b[36mQuadContourSet._check_xyz\u001b[39m\u001b[34m(self, x, y, z, kwargs)\u001b[39m\n\u001b[32m   1404\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m x.ndim == \u001b[32m2\u001b[39m:\n\u001b[32m   1405\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m x.shape != z.shape:\n\u001b[32m-> \u001b[39m\u001b[32m1406\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m   1407\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mShapes of x \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m and z \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mz.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m do not match\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1408\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m y.shape != z.shape:\n\u001b[32m   1409\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m   1410\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mShapes of y \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m and z \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mz.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m do not match\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: Shapes of x (65, 28) and z (28, 65) do not match"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARkAAAEYCAYAAABoTIKyAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAAGRtJREFUeJzt3H9M1Pf9B/Dn8TnvHHDe9Q5yYyaluqWmagUkGBwJslG2zAAlsya1zZJlqz9gicP2j4orCrYrF4tsJq2iqVmNCZjqGifTUdFssDAbjUWimNhai8RzBa545FDb4z68v3/0632lSOUD94I7v89H8km4N5/35/28O+4Z7tfHBECBiEhI3EwHIKJHG0uGiESxZIhIFEuGiESxZIhIFEuGiESxZIhIFEuGiESxZIhIFEuGiEQZLpmnnnoKR44cwY0bN6CUwqpVqwzNdzgcaGxsRCAQQG9vL6qrq41GIKIYYjY6ITExEdeuXUNjYyOOHDlieMF9+/Zh4cKFyMvLw9y5c9HQ0ACv14t9+/YZPhYRxQY12U0ppVatWjXh/V0ulwqFQmrlypXhsbq6OtXR0THpDNy4cYvuzfB/MlORkZEBTdPQ3t4eHmtra8PGjRthsVgQDAbHzLFYLLBaraPGnE4nBgYGxPMS/X9is9lw8+bNiB93WksmOTkZw8PDGBwcxJkzZ9De3o6jR49C0zQ4nU588cUXY+ZUVFSgqqpqOmMS/b81d+7ciBfNtJaMyWQK/3zjxg309fWNGnuQmpoa1NXVhS/bbDZ4vV488cQTGBwcFMsaCZqm4ZlnnsGpU6eg6/pMxxlXrOQEmFWK3W5Hd3c3AoFAxI89rSXT19eHWbNmwW63Y/Xq1QCAkpIS6Lo+7tOfYDD4wKdRg4OD8Pv9knGnTNM03L59G36/P6r/yGIlJ8CssUjkczJWqxWpqamw2+2jxjs6OqDrOnJycsJjubm5uHjx4gOLhIhin+GSmTVrFtLS0pCWlgYAeOKJJ5CWlga32x3eJzs7G93d3SgvLx8198svv8QHH3yAHTt2IDMzE8XFxVi3bh327NkztWtBRFHLcMn84Ac/wIULF3DhwgUAQG1tLS5cuIANGzZMaP66detw6dIltLa24t1338XOnTv5GRmiR5jh12SuX7/+0BdrW1tbx93H7/fj+eefN7osEcUofneJiESxZIhIFEuGiESxZIhIFEuGiESxZIhIFEuGiESxZIhIFEuGiESxZIhIFEuGiESxZIhIFEuGiESxZIhIFEuGiESxZIhIFEuGiESxZIhIFEuGiESxZIhIFEuGiESxZIhIFEuGiESxZIhIFEuGiESxZIhIFEuGiESxZIhIFEuGiESxZIhIFEuGiESxZIhIFEuGiESxZIhIFEuGiERNqmS2b9+O3t5eBAIBNDQ0YM6cOROeu3DhQnz44Yfw+/3o6+tDY2Mj3G73ZGIQUQwwXDJlZWXYtGkT1q5di7y8PKSnp6O+vn7C848dO4bbt29j2bJl+PnPf44f/ehHePfdd43GIKIYYbhk1q9fjz179uDYsWM4f/48Nm/ejNWrV8PpdD50blJSEn74wx/iz3/+Mz755BN0dHTgL3/5CzIzMycVnoiin9nIzhaLBYsWLcLWrVvDY21tbTCbzcjIyMDp06e/c77P58Ply5fx3HPP4cyZM5g9ezYKCwtx/Pjx71zTarWGL9tsNgCApmnQNM1I/GmnaRri4uKYM4KYVYZkRkMl43K5oGkafD4fPB4P8vPzkZWVhVAohOTk5Akdo6CgAEePHsWdO3cQFxeH48ePo6ysbNz9KyoqUFVV9cDjDA0NGYk/7TRNw9KlS2EymaDr+kzHGVes5ASYVUpiYqLYsQ2VjMlkCv/s8/nQ09NjeMG3334b169fR2lpKRISEvDWW2+hvr4ev/3tbx+4f01NDerq6sKXbTYbvF4vWlpa4Pf7Da8/nTRNg1IKzc3NUf1HFis5AWaV4nA4xI5tqGR8Ph90XUdSUhJqa2sBfBPObDajv7//ofNXrFiBZ599Fna7PfxfyO9//3ucOXMGr732Gv773/+OmRMMBhEMBseM67oe9XccAIyMjMRE1ljJCTCrBMl8hl74DQaD6OrqQk5OTngsNzcXoVAIHR0d4TGr1YrU1FTY7fZR8x977DEAgFIqPBYKhQAAs2fPNp6eiKKe4XeX9u7di9LSUhQVFSEzMxMejweHDx/GwMBAeJ/s7Gx0d3ejvLx81NwzZ84gEAigvr4eCxYsQHp6Ot566y10dXXh888/n/KVIaLoY+jpEgDs3r0bKSkp2L9/P+Lj49HU1ITS0tIJze3t7cXKlStRU1ODs2fP4uuvv8a///1v/OY3vzEcnIhig+GSAYDKykpUVlaO+/vW1tZRLxLf7z//+Q9WrFgxmWWJKAbxu0tEJIolQ0SiWDJEJIolQ0SiWDJEJIolQ0SiWDJEJIolQ0SiWDJEJIolQ0SiWDJEJIolQ0SiWDJEJIolQ0SiWDJEJIolQ0SiWDJEJIolQ0SiWDJEJIolQ0SiWDJEJIolQ0SiWDJEJIolQ0SiWDJEJIolQ0SiWDJEJIolQ0SiWDJEJIolQ0SiWDJEJIolQ0SiWDJEJIolQ0SiWDJEJGpSJbN9+3b09vYiEAigoaEBc+bMMTT/1VdfxWeffYavvvoKV69eRUlJyWRiEFEMMBudUFZWhk2bNuHFF1+E1+vFwYMHUV9fjxdeeGFC86urq1FWVoaNGzfio48+QnJyMoaHhw0HJ6LYoYxsnZ2daseOHeHLxcXFanh4WDmdzofOjY+PV0NDQ2rNmjWG1rx/s9lsSimlHA7HpI8xXZumaaqwsFBpmjbjWR6FnMwqtzkcDqWUUjabLeLHNvR0yWKxYNGiRWhvbw+PtbW1wWw2IyMj46Hzs7KykJCQAJPJhEuXLqGnpwcHDhyA0+k0EoOIYoihp0sulwuapsHn88Hj8SA/Px9ZWVkIhUJITk5+6PyUlBTouo4tW7bg5Zdfxu3bt/HOO+/gwIEDKCoqeuAci8UCq9Uavmyz2QAAmqZB0zQj8aedpmmIi4tjzghiVhmSGQ2VjMlkCv/s8/nQ09NjaLF7N7jH48HJkycBAJs3b8Y//vEP2O12DA4OjplTUVGBqqqqMeMFBQUYGhoytP500zQNS5cuhclkgq7rMx1nXLGSE2BWKYmJiWLHNlQyPp8Puq4jKSkJtbW1AACHwwGz2Yz+/v4JzQeATz75JDx27do1AMDcuXMfWDI1NTWoq6sLX7bZbPB6vWhpaYHf7zcSf9ppmgalFJqbm6P6jyxWcgLMKsXhcIgd21DJBINBdHV1IScnB3/7298AALm5uQiFQujo6AjvZ7Va8f3vfx9+v39UcXR2dmJkZATz58/H2bNnAQCPP/44AMDr9Y67ZjAYHDOu63rU33EAMDIyEhNZYyUnwKwSJPMZ/pzM3r17UVpaiqKiImRmZsLj8eDw4cMYGBgI75OdnY3u7m6Ul5ePmtvb24sTJ06guroay5cvx5IlS/DGG2/g+PHjD/wvhohin+HPyezevRspKSnYv38/4uPj0dTUhNLS0gnP//Wvf4133nkHzc3NCAaDaGlpwcaNG43GIKIYYbhkAKCyshKVlZXj/r61tXXUi8T3+/LLL/H8889PZlkiikH87hIRiWLJEJEolgwRiWLJEJEolgwRiWLJEJEolgwRiWLJEJEolgwRiWLJEJEolgwRiWLJEJEolgwRiWLJEJEolgwRiWLJEJEolgwRiWLJEJEolgwRiWLJEJEolgwRiWLJEJEolgwRiWLJEJEolgwRiWLJEJEolgwRiWLJEJEolgwRiWLJEJEolgwRiWLJEJEolgwRiWLJEJEolgwRiWLJEJGoSZXM9u3b0dvbi0AggIaGBsyZM8fwMcxmM86dOwelFFwu12RiEFEMMFwyZWVl2LRpE9auXYu8vDykp6ejvr7e8MLbtm3D7du3Dc8jothiuGTWr1+PPXv24NixYzh//jw2b96M1atXw+l0TvgYy5cvR3FxMf74xz8aXZ6IYozZyM4WiwWLFi3C1q1bw2NtbW0wm83IyMjA6dOnH3qMhIQEvPfee/jVr36F733vexNa02q1hi/bbDYAgKZp0DTNSPxpp2ka4uLimDOCmFWGZEZDJeNyuaBpGnw+HzweD/Lz85GVlYVQKITk5OQJHWPXrl04duwYzp49ixUrVjx0/4qKClRVVY0ZLygowNDQkJH4007TNCxduhQmkwm6rs90nHHFSk6AWaUkJiaKHdtQyZhMpvDPPp8PPT09hhYrKipCbm4ulixZMuE5NTU1qKurC1+22Wzwer1oaWmB3+83tP500zQNSik0NzdH9R9ZrOQEmFWKw+EQO7ahkvH5fNB1HUlJSaitrQXwTTiz2Yz+/v6Hzv/pT3+KefPm4datWwCAuLhvXhK6ceMGysvLsXfv3jFzgsEggsHgmHFd16P+jgOAkZGRmMgaKzkBZpUgmc/QC7/BYBBdXV3IyckJj+Xm5iIUCqGjoyM8ZrVakZqaCrvdPmr+m2++icWLFyM9PR3p6el46aWXAAB5eXk4dOjQVK4HEUUpw+8u7d27F6WlpSgqKkJmZiY8Hg8OHz6MgYGB8D7Z2dno7u5GeXn5qLn9/f24cuVKeLv3dOvq1asYHByc2jUhoqhk6OkSAOzevRspKSnYv38/4uPj0dTUhNLSUolsRPQIMFwyAFBZWYnKyspxf9/a2jrqReKp7kdEsYvfXSIiUSwZIhLFkiEiUSwZIhLFkiEiUSwZIhLFkiEiUSwZIhLFkiEiUSwZIhLFkiEiUSwZIhLFkiEiUSwZIhLFkiEiUSwZIhLFkiEiUSwZIhLFkiEiUSwZIhLFkiEiUSwZIhLFkiEiUSwZIhLFkiEiUSwZIhLFkiEiUSwZIhLFkiEiUSwZIhLFkiEiUSwZIhLFkiEiUSwZIhLFkiEiUZMqme3bt6O3txeBQAANDQ2YM2fOhOY5HA7s2bMH165dw507d/Dpp59iy5YtMJlMk4lBRDHAbHRCWVkZNm3ahBdffBFerxcHDx5EfX09XnjhhYfOdbvdcLlc+N3vfocrV65g8eLFOHDgAOLi4vDGG29M6goQUfRTRrbOzk61Y8eO8OXi4mI1PDysnE6noePc23bt2qU+/vjjCe9vs9mUUko5HI5JrTedm6ZpqrCwUGmaNuNZHoWczCq3ORwOpZRSNpst4sc29J+MxWLBokWLsHXr1vBYW1sbzGYzMjIycPr0aSOHA/DNfze3bt36zjWtVmv4ss1mAwBomgZN0wyvN500TUNcXBxzRhCzypDMaKhkXC4XNE2Dz+eDx+NBfn4+srKyEAqFkJycbHjxxYsXo6SkBL/85S/H3aeiogJVVVVjxgsKCjA0NGR4zemkaRqWLl0Kk8kEXddnOs64YiUnwKxSEhMTxY5tqGTuf4HW5/Ohp6dn0gu73W4cPXoUO3fuxIkTJ8bdr6amBnV1deHLNpsNXq8XLS0t8Pv9k15/OmiaBqUUmpubo/qPLFZyAswqxeFwiB3bUMn4fD7ouo6kpCTU1tYC+Cac2WxGf3//hI/jcrlw6tQpnDp1Cn/4wx++c99gMIhgMDhmXNf1qL/jAGBkZCQmssZKToBZJUjmM/QWdjAYRFdXF3JycsJjubm5CIVC6OjoCI9ZrVakpqbCbrePOYbD4UBLSwvOnz+PDRs2TCE6EcUCw5+T2bt3L0pLS1FUVITMzEx4PB4cPnwYAwMD4X2ys7PR3d2N8vLyUXNtNhtOnjyJvr4+VFRUwO12w+12IykpacpXhIiik+HPyezevRspKSnYv38/4uPj0dTUhNLS0gnNXbp0KbKysgAAN2/eDI93d3dj3rx5RqMQUQwwXDIAUFlZicrKynF/39ra+sBP8Y43TkSPLn53iYhEsWSISBRLhohEsWSISBRLhohEsWSISBRLhohEsWSISBRLhohEsWSISBRLhohEsWSISBRLhohEsWSISBRLhohEsWSISBRLhohEsWSISBRLhohEsWSISBRLhohEsWSISBRLhohEsWSISBRLhohEsWSISBRLhohEsWSISBRLhohEsWSISBRLhohEsWSISBRLhohEsWSISBRLhohETapktm/fjt7eXgQCATQ0NGDOnDkTnutwONDY2IhAIIDe3l5UV1dPJgIRxQjDJVNWVoZNmzZh7dq1yMvLQ3p6Ourr6yc8f9++fXj66aeRl5eHtWvX4pVXXsG6deuMxiCiGKKMbJ2dnWrHjh3hy8XFxWp4eFg5nc6HznW5XCoUCqmVK1eGx+rq6lRHR8eE17fZbEoppRwOh6HcM7FpmqYKCwuVpmkznuVRyMmscpvD4VBKKWWz2SJ+bDMMsFgsWLRoEbZu3Roea2trg9lsRkZGBk6fPv2d8zMyMqBpGtrb20fN37hxIywWC4LB4APXtFqt4cs2mw0AYLfbjUSfEZqmISEhAQ6HA7quz3ScccVKToBZpUg+ngyVjMvlgqZp8Pl88Hg8yM/PR1ZWFkKhEJKTkx86Pzk5GcPDwxgcHMSZM2fQ3t6Oo0ePQtM0OJ1OfPHFF2PmVFRUoKqqasx4d3e3kehENAFOpxOBQCCixzRUMiaTKfyzz+dDT0+PocXun3/jxg309fWNGnuQmpoa1NXVhS/bbDZ4vV7MnTs34jdGpMVK1ljJCTCrlHtZBwYGIn5sQyXj8/mg6zqSkpJQW1sL4Jt3i8xmM/r7+x86v6+vD7NmzYLdbsfq1asBACUlJdB1fdwrFwwGH/g0KhAIRP0dd0+sZI2VnACzxhJD7y4Fg0F0dXUhJycnPJabm4tQKISOjo7wmNVqRWpq6pjneR0dHdB1fcz8ixcvPrBIiOjRYOiV4rKyMhUIBFRRUZHKzMxUly9fVg0NDaP2WbFihVJKqW3bto2Z//7776tLly6pzMxMVVxcrIaGhtS6desmvP69d5ckXgWP9BYrWWMlJ7PGbFbjk15//XXV19enhoaGVGNjo7Lb7aN+/10l43A41KFDh9TQ0JDq6+tT1dXVhta2WCxq27ZtymKxzPgd86hkjZWczBqbWU3/+wMRkQh+d4mIRLFkiEgUS4aIRLFkiEhUVJVMLJ1CYrJZHQ4H9uzZg2vXruHOnTv49NNPsWXLlod+8nkmst7PbDbj3LlzUErB5XIJpJx6zldffRWfffYZvvrqK1y9ehUlJSUiOYGpZV24cCE+/PBD+P1+9PX1obGxEW63WyTnU089hSNHjuDGjRtQSmHVqlWG5kfqcTXjb58B//f5m+Li4nE/f/Nd21Q/fzNdWRcsWKDef/999Ytf/ELNnz9fFRcXq1u3bqnXXnst6rLev73++uvqX//6l1JKKZfLFXU5q6urVX9/v1qzZo2aN2+eWrZsmcrIyIjK2/Tq1avqgw8+UE8++aTKyMhQ586dU01NTSJZs7Ky1I4dO9SqVauUUkqtWrXK0PwIPa4if8Ums830KSSmK+uDtl27dqmPP/44arMuX75cdXZ2qoKCArGSmUrO+Ph4NTQ0pNasWSNyG0Yya1JSklJKqdzc3PBYWVmZunnzpnhuoyUTqcdVVDxduncKiW+fAuLeKSQeZrxTSDz99NOwWCxRlfVB3G43bt26FamIYZHImpCQgPfeew9r164V++rHVHNmZWUhISEBJpMJly5dQk9PDw4cOACn0xl1WX0+Hy5fvoznnnsOs2bNgs1mQ2FhIY4fPx7xrFMVqcdVVJTMt08hce7cOfj9/kmfQqK2thY+ny98ColoyvptixcvRklJCXbu3BnRnJHKumvXLhw7dgxnz56NeL5I5UxJSYGu69iyZQtefvllrFmzBmlpaThw4EDUZQWAgoICZGdn486dO+G5ZWVlEc86VZF6XEVFyczEKSQma6pZ7+d2u3H06FHs3LkTJ06ciES8UaaataioCLm5uaisrIx0tFGmmjMuLg6apsHj8eDkyZNob2/H5s2bUVhYGPGTMUXi/n/77bdx/fp1ZGdn4yc/+QncbrehU9hOl0g+rqbleex3bRaLRYVCIfXss8+Gx+6dDjA/P/+h85955hmllBr1HaqSkhIVCoUi/l2MqWa9t7lcLnXx4kVVX18ftbfrn/70JzU8PKzu3r2r7t69q77++mullFJ3795V69evj5qcP/vZz5RSSi1btiw89uSTTyqllFq4cGFU3aYrVqxQuq6rxMTE8Fh2drZSSqmUlBSxvwXA+GsykXpcRcV/MrF0CompZgW+eVuwpaUF58+fx4YNGyKaL5JZ33zzTSxevBjp6elIT0/HSy+9BADIy8vDoUOHoiZnZ2cnRkZGMH/+/PDY448/DgDwer0RyxmJrI899hgAQCkVHguFQgCA2bNnRzTrRE3H40q0PSe6zfQpJKYrq81mU2fPnlXNzc0qJSVFud1u5Xa7VVJSUtRl/fZ2bz/Jt7Anm7OpqUlduXJFLV++XC1ZskR99NFH6u9//3vU3aZut1v5/X518OBBtWDBApWenq7++c9/qkuXLolknTVrlkpLS1NpaWlKKaVeeeUVlZaWptxu94Ru10fqLWxgZk8hMV1Z741/2+effx51Wb+9SZbMVHO6XC516NAhNTg4qPr7+1VDQ4NYcU81649//GPV2tqqBgcHVV9fn/rrX/+q5s2bJ5IzNTX1gX9v9+eSflzxVA9EJCoqXpMhokcXS4aIRLFkiEgUS4aIRLFkiEgUS4aIRLFkiEgUS4aIRLFkiEgUS4aIRLFkiEgUS4aIRP0PCJdVKRR8CVUAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1600x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot some examples\n",
    "n_plot = 3\n",
    "rand_idxs = np.random.randint(0, N, n_plot)\n",
    "for i, ri in enumerate(rand_idxs):\n",
    "    plt.figure(figsize=(16, 3))\n",
    "    plt.subplot(1, 5, 1)\n",
    "    plt.contourf(RRD, ZZD, Fx[ri], levels=20)\n",
    "    plt.axis('equal'), plt.axis('off')\n",
    "    plt.title('Fx')\n",
    "    plt.colorbar()\n",
    "    plt.subplot(1, 5, 2)\n",
    "    plt.contourf(RRD, ZZD, Iy[ri], levels=20)\n",
    "    plt.axis('equal'), plt.axis('off')\n",
    "    plt.title('Iy')\n",
    "    plt.colorbar()\n",
    "    plt.subplot(1, 5, 3)\n",
    "    plt.bar(np.arange(Ia.shape[1]), Ia[ri])\n",
    "    plt.title('Ia')\n",
    "    plt.subplot(1, 5, 4)\n",
    "    plt.bar(np.arange(Bm.shape[1]), Bm[ri])\n",
    "    plt.title('Bm')\n",
    "    plt.subplot(1, 5, 5)\n",
    "    plt.bar(np.arange(Uf.shape[1]), Uf[ri])\n",
    "    plt.title('Uf')\n",
    "    plt.tight_layout()\n",
    "    plt.suptitle(f'SHOT {ri}')\n",
    "    plt.show() if HAS_SCREEN else plt.savefig(f'{DATA_DIR}/example_{i}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test interpolation\n",
    "idx = np.random.randint(0, N)\n",
    "f, rhs = Fx[idx,:,:], Iy[idx,:,:]\n",
    "rrg, zzg = sample_random_subgrid(RRD,ZZD, N_GRID_Z, N_GRID_R)\n",
    "print(f.shape, rhs.shape, rrg.shape, zzg.shape)\n",
    "box = get_box_from_grid(rrg, zzg)\n",
    "f_grid = interp_fun(Fx[idx,:,:], RRD, ZZD, rrg, zzg)\n",
    "rhs_grid = interp_fun(rhs, RRD, ZZD, rrg, zzg)\n",
    "\n",
    "fig,ax = plt.subplots(1,5, figsize=(20,5))\n",
    "ax[0].scatter(RRD, ZZD, marker='.')\n",
    "ax[0].scatter(rrg, zzg, marker='.')\n",
    "ax[0].set_aspect('equal')\n",
    "\n",
    "im1 = ax[1].contourf(RRD, ZZD, f, 20)\n",
    "ax[1].plot(box[:,0],box[:,1])\n",
    "ax[1].set_aspect('equal')\n",
    "\n",
    "im2 = ax[2].contourf(rrg, zzg, f_grid, 20)\n",
    "ax[2].set_aspect('equal')\n",
    "\n",
    "im3 = ax[3].contourf(RRD, ZZD, rhs, 20)\n",
    "ax[3].set_aspect('equal')\n",
    "ax[3].plot(box[:,0],box[:,1])\n",
    "\n",
    "im4 = ax[4].contourf(rrg, zzg, rhs_grid, 20)\n",
    "ax[4].set_aspect('equal')\n",
    "\n",
    "plt.colorbar(im1,ax=ax[1])\n",
    "plt.colorbar(im2,ax=ax[2])\n",
    "plt.colorbar(im3,ax=ax[3])\n",
    "plt.colorbar(im4,ax=ax[4])\n",
    "\n",
    "plt.show() if HAS_SCREEN else plt.savefig(join(DATA_DIR, 'interpolation_example.png'))\n",
    "\n",
    "plt.figure(figsize=(5,10))\n",
    "rrg = rrg.reshape(-1)\n",
    "zzg = zzg.reshape(-1)\n",
    "plt.plot(rrg, zzg)\n",
    "plt.scatter(rrg, zzg, c=np.linspace(0,1,N_GRID_R*N_GRID_Z), cmap='inferno')\n",
    "plt.scatter(rrg[0], zzg[0], c='r', marker='o')\n",
    "plt.scatter(rrg[-1], zzg[-1], c='b', marker='o')\n",
    "plt.axis('equal')\n",
    "plt.title('Subgrid')\n",
    "plt.show() if HAS_SCREEN else plt.savefig(join(DATA_DIR, 'subgrid_example.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset splitting (N_TOP = original dataset size)\n",
    "NT = int(N_SAMPLES*TRAIN_EVAL_SPLIT)    # training\n",
    "NE = N_SAMPLES - NT                     # evaluation\n",
    "NTF = int(NT*FULL_SUBGRID_SPLIT)        # training full\n",
    "NTS = NT - NTF                          # training subgrid\n",
    "NEF = int(NE*FULL_SUBGRID_SPLIT)        # evaluation full\n",
    "NES = NE - NEF                          # evaluation subgrid \n",
    "assert NTF+NTS == NT\n",
    "assert NEF+NES == NE\n",
    "assert NTF + NTS + NEF + NES == N_SAMPLES\n",
    "print(f\"Training: {NT}, full: {NTF}, subgrid: {NTS}\")\n",
    "print(f\"Eval:     {NE}, full: {NEF}, subgrid: {NES}\")\n",
    "orig_idxs = np.random.permutation(N)\n",
    "orig_idxs_train = orig_idxs[:int(N*TRAIN_EVAL_SPLIT)] # original indices for training\n",
    "orig_idxs_eval = orig_idxs[int(N*TRAIN_EVAL_SPLIT):] # original indices for evaluation\n",
    "# splitting the idxs\n",
    "assert len(orig_idxs_train) > NTF, f\"Training set is too small, {len(orig_idxs_train)} < {NTF}\"\n",
    "idxs_tf = np.random.choice(orig_idxs_train, NTF, replace=False) # training full\n",
    "assert len(orig_idxs_train) > NTS, f\"Training set is too small, {len(orig_idxs_train)} < {NTS}\"\n",
    "idxs_ts = np.random.choice(orig_idxs_train, NTS, replace=False) # can overlap with idxs_tf\n",
    "assert len(orig_idxs_eval) > NEF, f\"Evaluation set is too small, {len(orig_idxs_eval)} < {NEF}\"\n",
    "idxs_ef = np.random.choice(orig_idxs_eval, NEF, replace=False) # evaluation full\n",
    "assert len(orig_idxs_eval) > NES, f\"Evaluation set is too small, {len(orig_idxs_eval)} < {NES}\"\n",
    "idxs_es = np.random.choice(orig_idxs_eval, NES, replace=False) # can overlap with idxs_ef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create arrays to store the dataset\n",
    "# x_tf = [np.zeros((NTF, *x[0].shape), dtype=DTYPE) for x in X]\n",
    "# y_tf = np.zeros((NTF, N_GRID_Z, N_GRID_R), dtype=DTYPE)\n",
    "# rr_tf = np.zeros((NTF, N_GRID_Z, N_GRID_R), dtype=DTYPE)\n",
    "# zz_tf = np.zeros((NTF, N_GRID_Z, N_GRID_R), dtype=DTYPE)\n",
    "# rhs_tf = np.zeros((NTF, N_GRID_Z, N_GRID_R), dtype=DTYPE)\n",
    "\n",
    "x_ts = [np.zeros((NTS, *x[0].shape), dtype=DTYPE) for x in X]\n",
    "y_ts = np.zeros((NTS, N_GRID_Z, N_GRID_R), dtype=DTYPE)\n",
    "rr_ts = np.zeros((NTS, N_GRID_Z, N_GRID_R), dtype=DTYPE)\n",
    "zz_ts = np.zeros((NTS, N_GRID_Z, N_GRID_R), dtype=DTYPE)\n",
    "rhs_ts = np.zeros((NTS, N_GRID_Z, N_GRID_R), dtype=DTYPE)\n",
    "\n",
    "# x_ef = [np.zeros((NEF, *x[0].shape), dtype=DTYPE) for x in X]\n",
    "# y_ef = np.zeros((NEF, N_GRID_Z, N_GRID_R), dtype=DTYPE)\n",
    "# rr_ef = np.zeros((NEF, N_GRID_Z, N_GRID_R), dtype=DTYPE)\n",
    "# zz_ef = np.zeros((NEF, N_GRID_Z, N_GRID_R), dtype=DTYPE)\n",
    "# rhs_ef = np.zeros((NEF, N_GRID_Z, N_GRID_R), dtype=DTYPE)\n",
    "\n",
    "x_es = [np.zeros((NES, *x[0].shape), dtype=DTYPE) for x in X]\n",
    "y_es = np.zeros((NES, N_GRID_Z, N_GRID_R), dtype=DTYPE)\n",
    "rr_es = np.zeros((NES, N_GRID_Z, N_GRID_R), dtype=DTYPE)\n",
    "zz_es = np.zeros((NES, N_GRID_Z, N_GRID_R), dtype=DTYPE)\n",
    "rhs_es = np.zeros((NES, N_GRID_Z, N_GRID_R), dtype=DTYPE)\n",
    "\n",
    "## fill the arrays\n",
    "# # Train Full -> just copy the data\n",
    "# for ix, x in enumerate(X): x_tf[ix][:] = x[idxs_tf]\n",
    "# y_tf[:], rhs_tf[:] = Y[idxs_tf], RHS[idxs_tf]\n",
    "# rr_tf[:], zz_tf[:] = RRD, ZZD\n",
    "# Train Subgrid -> interpolate the data\n",
    "for ix, x in enumerate(X): x_ts[ix][:] = x[idxs_ts]\n",
    "start_time = time()\n",
    "for i, idx in enumerate(idxs_ts):\n",
    "    (yi, rhsi), rri, zzi = resample_on_new_subgrid([Y[idx], RHS[idx]], RRD, ZZD, N_GRID_Z, N_GRID_R)\n",
    "    y_ts[i], rhs_ts[i], rr_ts[i], zz_ts[i] = yi, rhsi, rri, zzi\n",
    "    if (i+1) % 1000 == 0: print(f\"Train Subgrid: {i+1}/{NTS}, eta: {((time()-start_time)/(i+1)*(NTS-i-1))/60:.1f} min\", flush=True)\n",
    "# # Eval Full -> just copy the data\n",
    "# for ix, x in enumerate(X): x_ef[ix][:] = x[idxs_ef]\n",
    "# y_ef[:], rhs_ef[:] = Y[idxs_ef], RHS[idxs_ef]\n",
    "# rr_ef[:], zz_ef[:] = RRD, ZZD\n",
    "# Eval Subgrid -> interpolate the data\n",
    "for ix, x in enumerate(X): x_es[ix][:] = x[idxs_es]\n",
    "start_time = time()\n",
    "for i, idx in enumerate(idxs_es):\n",
    "    (yi, rhsi), rri, zzi = resample_on_new_subgrid([Y[idx], RHS[idx]], RRD, ZZD, N_GRID_Z, N_GRID_R)\n",
    "    y_es[i], rhs_es[i], rr_es[i], zz_es[i] = yi, rhsi, rri, zzi\n",
    "    if (i+1) % 1000 == 0: print(f\"Eval Subgrid: {i+1}/{NES}, eta: {((time()-start_time)/(i+1)*(NES-i-1))/60:.1f} min\", flush=True)\n",
    "\n",
    "# concatenate the arrays\n",
    "X_train = x_ts\n",
    "y_train = y_ts\n",
    "rr_train = rr_ts\n",
    "zz_train = zz_ts\n",
    "rhs_train = rhs_ts\n",
    "del x_ts, y_ts, rr_ts, zz_ts, rhs_ts\n",
    "\n",
    "X_eval = x_es\n",
    "y_eval = y_es\n",
    "rr_eval = rr_es\n",
    "zz_eval = zz_es\n",
    "rhs_eval = rhs_es\n",
    "del x_es, y_es, rr_es, zz_es, rhs_es\n",
    "print(f\"x_train: [{[x.shape for x in X_train]}], y_train: {y_train.shape}, rr_train: {rr_train.shape}, zz_train: {zz_train.shape}, rhs_train: {rhs_train.shape}\")\n",
    "print(f\"x_eval: [{[x.shape for x in X_eval]}], y_eval: {y_eval.shape}, rr_eval: {rr_eval.shape}, zz_eval: {zz_eval.shape}, rhs_eval: {rhs_eval.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate kernels for Grad-Shafranov equation\n",
    "# so we don't have to do it during training\n",
    "laplace_ker_t = np.zeros((len(X_train[0]), 3, 3), dtype=DTYPE)\n",
    "laplace_ker_e = np.zeros((len(X_eval[0]), 3, 3), dtype=DTYPE)\n",
    "df_dr_ker_t = np.zeros((len(X_train[0]), 3, 3), dtype=DTYPE)\n",
    "df_dr_ker_e = np.zeros((len(X_eval[0]), 3, 3), dtype=DTYPE)\n",
    "hrs_t, hzs_t = rr_train[:,1,2]-rr_train[:,1,1], zz_train[:,2,1]-zz_train[:,1,1]\n",
    "hrs_e, hzs_e = rr_eval[:,1,2]-rr_eval[:,1,1], zz_eval[:,2,1]-zz_eval[:,1,1]\n",
    "for i in range(len(X_train[0])):\n",
    "    try:\n",
    "        laplace_ker_t[i,:,:], df_dr_ker_t[i,:,:] = calc_laplace_df_dr_ker(hrs_t[i], hzs_t[i])\n",
    "    except Exception as e:\n",
    "        print(f\"Error calculating laplace_ker_t for index {i}: {e}\")\n",
    "        # plot rr_train[i], zz_train[i]\n",
    "        plt.figure()\n",
    "        plt.scatter(rr_train[i], zz_train[i], marker='.')\n",
    "        plt.title(f\"rr_train[{i}]\")\n",
    "        plt.axis('equal')\n",
    "        plt.show() if HAS_SCREEN else plt.savefig(f'{DATA_DIR}/rr_train_{i}.png')\n",
    "        # plot rr_eval[i], zz_eval[i]\n",
    "        break\n",
    "\n",
    "for i in range(len(X_eval[0])):\n",
    "    laplace_ker_e[i,:,:], df_dr_ker_e[i,:,:] = calc_laplace_df_dr_ker(hrs_e[i], hzs_e[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the dataset\n",
    "rows = 5\n",
    "idxs_train = np.random.randint(0, len(X_train[0]), rows)\n",
    "idxs_eval = np.random.randint(0, len(X_eval[0]), rows)\n",
    "fig,ax = plt.subplots(rows,6, figsize=(15,3*rows))\n",
    "box0 = get_box_from_grid(RRD, ZZD)\n",
    "for i, (it, ie)  in enumerate(zip(idxs_train, idxs_eval)):\n",
    "    # training\n",
    "    boxi = get_box_from_grid(rr_train[it], zz_train[it])\n",
    "    ax[i,0].plot(box0[:,0], box0[:,1])\n",
    "    ax[i,0].plot(boxi[:,0], boxi[:,1])\n",
    "    ax[i,0].set_aspect('equal')\n",
    "    ax[i,0].set_title(f\"Train {it}\")\n",
    "    a1 = ax[i,1].contourf(rr_train[it], zz_train[it], y_train[it], 20)\n",
    "    ax[i,1].plot(box0[:,0], box0[:,1])\n",
    "    ax[i,1].set_aspect('equal')\n",
    "    plt.colorbar(a1,ax=ax[i,1])\n",
    "    a2 = ax[i,2].contourf(rr_train[it], zz_train[it] ,-rhs_train[it], 20)\n",
    "    ax[i,2].plot(box0[:,0], box0[:,1])\n",
    "    ax[i,2].set_aspect('equal')\n",
    "    plt.colorbar(a2,ax=ax[i,2])\n",
    "    # evaluation\n",
    "    boxi = get_box_from_grid(rr_eval[ie], zz_eval[ie])\n",
    "    ax[i,3].plot(box0[:,0], box0[:,1])\n",
    "    ax[i,3].plot(boxi[:,0], boxi[:,1])\n",
    "    ax[i,3].set_aspect('equal')\n",
    "    ax[i,3].set_title(f\"Eval {ie}\")\n",
    "    a1 = ax[i,4].contourf(rr_eval[ie], zz_eval[ie], y_eval[ie], 20)\n",
    "    ax[i,4].plot(box0[:,0], box0[:,1])\n",
    "    ax[i,4].set_aspect('equal')\n",
    "    plt.colorbar(a1,ax=ax[i,4])\n",
    "    a2 = ax[i,5].contourf(rr_eval[ie], zz_eval[ie] ,-rhs_eval[ie], 20)\n",
    "    ax[i,5].plot(box0[:,0], box0[:,1])\n",
    "    ax[i,5].set_aspect('equal')\n",
    "    plt.colorbar(a2,ax=ax[i,5])\n",
    "plt.show() if HAS_SCREEN else plt.savefig(join(DATA_DIR, 'dataset_check.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import calc_gso, calc_gso_batch\n",
    "import torch\n",
    "n_plots = 7\n",
    "idxs = np.random.randint(0, len(X_train[0]), n_plots)\n",
    "psis, rhss = y_train[idxs], rhs_train[idxs]\n",
    "rrs, zzs = rr_train[idxs], zz_train[idxs]\n",
    "big_box = get_box_from_grid(RRD, ZZD)\n",
    "#batched version\n",
    "psist = torch.tensor(psis, dtype=torch.float32).view(n_plots, 1, N_GRID_Z, N_GRID_R)\n",
    "rrst = torch.tensor(rrs, dtype=torch.float32).view(n_plots, 1, N_GRID_Z, N_GRID_R)\n",
    "zzst = torch.tensor(zzs, dtype=torch.float32).view(n_plots, 1, N_GRID_Z, N_GRID_R)\n",
    "print(f'psi: {psist.shape}, rr: {rrst.shape}, zz: {zzst.shape}')\n",
    "gsos = calc_gso_batch(psist, rrst, zzst)\n",
    "print(f'gsos: {gsos.shape}')\n",
    "gsos = gsos.view(n_plots, N_GRID_Z, N_GRID_R).numpy()\n",
    "# single version\n",
    "for i in range(n_plots):\n",
    "    psi, rr, zz, rhs = psis[i], rrs[i], zzs[i], rhss[i]\n",
    "    box = get_box_from_grid(rr, zz)\n",
    "    gso = calc_gso(psi, rr, zz) # calculate the Grad-Shafranov operator\n",
    "    gso2 = gsos[i]\n",
    "    #plot error gso vs gso2\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "    im = ax.contourf(rr, zz, np.abs(gso-gso2), 20)\n",
    "    ax.plot(big_box[:,0], big_box[:,1])\n",
    "    ax.set_aspect('equal')\n",
    "    ax.set_title(f\"Error batch/no batch {i}\")\n",
    "    plt.colorbar(im, ax=ax)\n",
    "    plt.show() if HAS_SCREEN else plt.savefig(join(DATA_DIR, f'gso_error_{i}.png'))\n",
    "    # NOTE: the error between the batched and non-batched version can be non-zero due to different\n",
    "    # implementations in gpu\n",
    "    print(f\"max error batch/no batch: {np.abs(gso-gso2).max()}\")\n",
    "    # assert np.allclose(gso, gso2, rtol=1e-2), f\"Error in the calculation of the Grad-Shafranov operator: \\ngso:\\n{gso}, \\ngso2:\\n{gso2}\"\n",
    "    # psi, gso, rhs = psi[1:-1,1:-1], gso[1:-1,1:-1], rhs[1:-1,1:-1]\n",
    "    # rr, zz = rr[1:-1,1:-1], zz[1:-1,1:-1] \n",
    "    fig,ax = plt.subplots(1,5, figsize=(20,5))\n",
    "    ax[0].plot(big_box[:,0], big_box[:,1])\n",
    "    ax[0].plot(box[:,0], box[:,1])\n",
    "    ax[0].set_aspect('equal')\n",
    "    ax[0].set_xticks([]), ax[0].set_yticks([])\n",
    "    ax[0].set_title(f\"Train {idxs}\")\n",
    "    im1 = ax[1].contourf(rr, zz, psi, 20)\n",
    "    ax[1].plot(big_box[:,0], big_box[:,1])\n",
    "    ax[1].set_aspect('equal')\n",
    "    ax[1].set_xticks([]), ax[1].set_yticks([])\n",
    "    ax[1].set_title(\"Î¨\")\n",
    "    im2 = ax[2].contourf(rr, zz, -gso, 20)\n",
    "    ax[2].plot(big_box[:,0], big_box[:,1])\n",
    "    ax[2].set_aspect('equal')\n",
    "    ax[2].set_xticks([]), ax[2].set_yticks([])\n",
    "    ax[2].set_title(\"GSO recalculated\")\n",
    "    im3 = ax[3].contourf(rr, zz, -rhs, 20)\n",
    "    ax[3].plot(big_box[:,0], big_box[:,1])\n",
    "    ax[3].set_aspect('equal')\n",
    "    ax[3].set_xticks([]), ax[3].set_yticks([])\n",
    "    ax[3].set_title(\"GSO from dataset\")\n",
    "    im4 = ax[4].contourf(rr, zz, np.abs(gso-rhs), 20)\n",
    "    ax[4].plot(big_box[:,0], big_box[:,1])\n",
    "    ax[4].set_aspect('equal')\n",
    "    ax[4].set_xticks([]), ax[4].set_yticks([])\n",
    "    ax[4].set_title(\"Absolute error\")\n",
    "    plt.colorbar(im1,ax=ax[1])\n",
    "    plt.colorbar(im2,ax=ax[2])\n",
    "    plt.colorbar(im3,ax=ax[3])\n",
    "    plt.colorbar(im4,ax=ax[4])\n",
    "    plt.show() if HAS_SCREEN else plt.savefig(join(DATA_DIR, f'gso_check_{i}.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert y_train.shape[1:] == (N_GRID_R, N_GRID_Z), f\"X_train shape mismatch: {X_train[0].shape[1:]} != ({N_GRID_R}, {N_GRID_Z})\"\n",
    "assert y_eval.shape[1:] == (N_GRID_R, N_GRID_Z), f\"X_eval shape mismatch: {X_eval[0].shape[1:]} != ({N_GRID_R}, {N_GRID_Z})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset anc calculate statistics\n",
    "curr = X_train[0] # coil currents\n",
    "mag = X_train[1] # magnetic probe measurements\n",
    "prof = X_train[2] # flux loop poloidal flux\n",
    "\n",
    "\n",
    "curr_mean_std = np.vstack([np.mean(curr, axis=0), np.std(curr, axis=0)])\n",
    "mag_mean_std = np.vstack([np.mean(mag, axis=0), np.std(mag, axis=0)])\n",
    "prof_mean_std = np.vstack([np.mean(prof, axis=0), np.std(prof, axis=0)])\n",
    "\n",
    "print(f'curr_mean_std: {curr_mean_std.shape}, mag_mean_std: {mag_mean_std.shape}, prof_mean_std: {prof_mean_std.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the datasets as mat files\n",
    "train_ds_path = join(DATA_DIR, f'train_ds_{N_SAMPLES}_{TRAIN_EVAL_SPLIT*100:.0f}_{FULL_SUBGRID_SPLIT*100:.0f}.mat')\n",
    "eval_ds_path = join(DATA_DIR, f'eval_ds_{N_SAMPLES}_{TRAIN_EVAL_SPLIT*100:.0f}_{FULL_SUBGRID_SPLIT*100:.0f}.mat')\n",
    "savemat(train_ds_path, {\n",
    "        'currs':curr, \n",
    "        'currs_mean_std':curr_mean_std,\n",
    "        'magnetic':mag, \n",
    "        'magnetic_mean_std':mag_mean_std,\n",
    "        'profiles':prof, \n",
    "        'profiles_mean_std':prof_mean_std,\n",
    "        'psi':y_train, \n",
    "        'rr':rr_train, \n",
    "        'zz':zz_train,\n",
    "        })\n",
    "savemat(eval_ds_path, {\n",
    "        'currs':X_eval[0],\n",
    "        'currs_mean_std':curr_mean_std,\n",
    "        'magnetic':X_eval[1], \n",
    "        'magnetic_mean_std':mag_mean_std,\n",
    "        'profiles':X_eval[2], \n",
    "        'profiles_mean_std':prof_mean_std,\n",
    "        'psi':y_eval, \n",
    "        'rr':rr_eval, \n",
    "        'zz':zz_eval\n",
    "        })\n",
    "print(\"Pytorch (.mat) dataset saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove this part\n",
    "os.system(f'cp {train_ds_path} dss/train_ds.mat')\n",
    "os.system(f'cp {eval_ds_path} dss/eval_ds.mat')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
